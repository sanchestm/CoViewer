{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25bf32fc-f946-42c0-8535-a1d77d20269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import argv\n",
    "import sys\n",
    "#from PyQt5 import QtCore, QtGui, uic, QtWidgets\n",
    "#from PyQt5.QtWebEngineWidgets import *\n",
    "#from PyQt5.QtCore import QUrl\n",
    "import numpy as np\n",
    "from jupyter_dash import JupyterDash\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "from sklearn import linear_model\n",
    "plt.rcParams[\"figure.figsize\"] = (15,15)\n",
    "import math\n",
    "import seaborn as sns\n",
    "import shap\n",
    "#from datetime import datetime\n",
    "import time\n",
    "from ipywidgets.embed import embed_minimal_html\n",
    "from umap import UMAP\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from prophet import Prophet\n",
    "import umap\n",
    "from lightgbm import LGBMRegressor,LGBMClassifier\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.manifold import *\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import estimator_html_repr\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.linear_model import *\n",
    "import networkx as nx\n",
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "import calendar\n",
    "from prophet.utilities import regressor_coefficients\n",
    "import plotly.express as px\n",
    "#from jupyter_dash import JupyterDash\n",
    "import dash_core_components as dcc\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "import base64\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import io\n",
    "import dash\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_html_components as html\n",
    "import dash_core_components as dcc\n",
    "import dash_table\n",
    "import dash_cytoscape as cyto\n",
    "from dash.exceptions import PreventUpdate\n",
    "from keplergl import KeplerGl\n",
    "import hdbscan\n",
    "import datetime\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.stats import ttest_ind, ttest_1samp\n",
    "from dash_table.Format import Format, Scheme, Trim\n",
    "from sklearn.compose import make_column_transformer\n",
    "from ipywidgets import AppLayout, Button, Layout, Accordion\n",
    "from ipywidgets import Button, Layout, jslink, IntText, IntSlider, HBox, VBox\n",
    "from ipywidgets import GridspecLayout\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.manifold import *\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from umap import UMAP\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.linear_model import *\n",
    "from joblib import Memory\n",
    "from shutil import rmtree\n",
    "import sklearn\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import auc,confusion_matrix,plot_confusion_matrix,classification_report\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from skopt import BayesSearchCV, gp_minimize, forest_minimize, gbrt_minimize\n",
    "from skopt.searchcv import BayesSearchCV as BSCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import set_config\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, StratifiedKFold, KFold\n",
    "from skopt.plots import plot_objective\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.plots import plot_convergence\n",
    "from sklearn.feature_selection import RFECV\n",
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "set_config(display='diagram')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#matplotlib.style.use('seaborn')\n",
    "from sklearn import linear_model\n",
    "import math\n",
    "import seaborn as sns\n",
    "import shap\n",
    "#from datetime import datetime\n",
    "import time\n",
    "import ipywidgets as widget\n",
    "import dash_html_components as html\n",
    "from sklearn.base import clone\n",
    "import dash_bio as dashbio\n",
    "\n",
    "\n",
    "import gzip\n",
    "\n",
    "def get_vcf_names(vcf_path):\n",
    "    with gzip.open(vcf_path, \"rt\") as ifile:\n",
    "          for line in ifile:\n",
    "            if line.startswith(\"#CHROM\"):\n",
    "                vcf_names = [x for x in line.split('\\t')]\n",
    "                break\n",
    "            \n",
    "    ifile.close()\n",
    "    return vcf_names\n",
    "\n",
    "def _force_plot_htmlsm(*args):\n",
    "    force_plot = shap.force_plot(*args, matplotlib=False)\n",
    "    shap_html = f\"<head>{shap.getjs()}</head><body>{force_plot.html()}</body>\"\n",
    "    return html.Iframe(srcDoc=shap_html,style={\"width\": \"100%\", \"height\": \"400px\", \"border\": 0})\n",
    "\n",
    "\n",
    "class pipemaker2:\n",
    "    def __init__(self, df,ipt_pipe, target ,*, height = 'auto', width = 'auto'):\n",
    "        self.pipe_list = []\n",
    "\n",
    "        ###### Dataframe\n",
    "        self.df = df\n",
    "\n",
    "        ###### App\n",
    "        self.target = widget.Select(options = list(self.df.columns), description = 'Target',rows=1 ,layout=Layout(height='auto', width='33%'))\n",
    "        self.target.value = target\n",
    "        self.TG = target\n",
    "        self.classifier = widget.Select(options = ['LGBMClassifier', 'LGBMRegressor'] + sklearn.ensemble.__all__ + sklearn.linear_model.__all__, description = 'Classifier',rows=1, layout=Layout(height='auto', width='33%'))\n",
    "\n",
    "\n",
    "        #### add column buttons\n",
    "        self.nColumns = widget.BoundedIntText( value=1,min=1,step=1,description='Number of column transformers:' ,layout=Layout(height='auto', width='33%'))\n",
    "        self.nColumns.observe(self.maketab, \"value\")\n",
    "\n",
    "        self.top_box = HBox([self.nColumns, self.target, self.classifier],layout=Layout(height='auto', width='100%'))\n",
    "\n",
    "        self.acc_list = [self.makeacc()]\n",
    "        self.check = 0\n",
    "\n",
    "        self.tab = widget.Tab()\n",
    "        self.tab.set_title(0, '0')\n",
    "        self.tab.children = self.acc_list\n",
    "        self.widget = VBox([self.top_box, self.tab])\n",
    "\n",
    "        self.cached_pipe = 0\n",
    "        self.location = 0\n",
    "        self.memory = 0\n",
    "        self.optimized_pipe = (0, 0)\n",
    "        self.input_pipe = ipt_pipe\n",
    "\n",
    "\n",
    "    def makeacc(self):\n",
    "        accordion = widget.Accordion(children=[\n",
    "            widget.Text(str(self.nColumns.value)),\n",
    "            widget.SelectMultiple(options=self.df.columns.values, description='columns',rows=len(self.df.columns)),\n",
    "            widget.Text(''),\n",
    "            widget.ToggleButtons(options= ['None'] + [x for x in sklearn.preprocessing.__all__ if x[0].isupper() ]  ),\n",
    "            widget.ToggleButtons(options= ['None'] +  [x for x in sklearn.decomposition.__all__ if x[0].isupper() ]  ),\n",
    "            widget.ToggleButtons(options= ['None', 'UMAP'] + [x for x in sklearn.manifold.__all__ if x[0].isupper() ] )\n",
    "        ])\n",
    "        accordion.set_title(0, 'Name of transformer')\n",
    "        accordion.set_title(1, 'Column to be transformed')\n",
    "        accordion.set_title(2, 'Manual input')\n",
    "        accordion.set_title(3, 'Sklearn preprocessing')\n",
    "        accordion.set_title(4, 'Sklearn decomposition')\n",
    "        accordion.set_title(5, 'Sklearn manifold')\n",
    "        accordion.selected_index = None\n",
    "        return accordion\n",
    "\n",
    "\n",
    "    def accordion_to_tuple(self, acc):\n",
    "\n",
    "        if acc.children[-4].value == '': transformer_list = [eval(x.value + '()') for x in acc.children[-3:] if x.value !='None' ]\n",
    "        else: transformer_list = eval('[' + acc.children[-4].value+ ']')\n",
    "\n",
    "        if len(transformer_list) > 0: pipe = make_pipeline( *transformer_list)\n",
    "        else: pipe = Pipeline(steps = [('empty','passthrough')])\n",
    "\n",
    "        self.check = (acc.children[0].value, pipe, tuple(acc.children[1].value))\n",
    "\n",
    "        return (acc.children[0].value, pipe,tuple(acc.children[1].value))\n",
    "\n",
    "\n",
    "    def maketab(self, change):\n",
    "        if self.nColumns.value > len(self.acc_list):\n",
    "             self.acc_list += [self.makeacc() for i in range(self.nColumns.value - len(self.acc_list))]\n",
    "\n",
    "        elif self.nColumns.value < len(self.acc_list):\n",
    "            self.acc_list = self.acc_list[:self.nColumns.value]\n",
    "\n",
    "\n",
    "        self.tab.children = self.acc_list\n",
    "        for num, acc in enumerate(self.acc_list):\n",
    "            self.tab.set_title(num, str(acc.children[0].value))\n",
    "        self.widget = VBox([self.top_box, self.tab])\n",
    "\n",
    "    def Pipe(self):\n",
    "        return clone(self.input_pipe) #Pipeline(steps = [('preprocessing', self.ColumnTransform()), ('classifier', eval(self.classifier.value + '()') )])\n",
    "\n",
    "    def Cache_pipe(self):\n",
    "        self.location = 'cachedir'\n",
    "        self.memory = Memory(location=self.location, verbose=0)\n",
    "        self.cached_pipe = self.Pipe().set_params(memory = self.memory)\n",
    "\n",
    "    def release_cache(self):\n",
    "        self.memory.clear(warn=True)\n",
    "        rmtree(self.location)\n",
    "        del self.memory\n",
    "\n",
    "    def display_app(self):\n",
    "        display(self.widget)\n",
    "\n",
    "    def ColumnTransform(self):\n",
    "        return ColumnTransformer([self.accordion_to_tuple(aco) for aco in self.acc_list])\n",
    "\n",
    "\n",
    "    def export_kwards(self):\n",
    "        return self.Pipe().get_params()\n",
    "    def fit_transform(self):\n",
    "        return self.ColumnTransform().fit_transform(self.df)\n",
    "    def fit_predict(self):\n",
    "        return self.Pipe().fit_predict(self.df, self.df[self.TG])\n",
    "    def fit(self):\n",
    "        return self.Pipe().fit(self.df, self.df[self.TG])\n",
    "\n",
    "    def RFECV(self):\n",
    "        preprocessed_df = pd.DataFrame(self.Pipe()['preprocessing'].fit_transform(self.df))\n",
    "\n",
    "        if self.optimized_pipe[1] == 0:\n",
    "            selector = RFECV(self.Pipe()['classifier'], step=1, cv=KFold(10, shuffle= True)).fit(preprocessed_df, self.df[self.TG])\n",
    "        else:\n",
    "            selector = RFECV(self.optimized_pipe[0]['classifier'], step=1, cv=KFold(10, shuffle= True)).fit(preprocessed_df, self.df[self.TG])\n",
    "\n",
    "        hX = np.array( range(1, len(selector.grid_scores_) + 1))\n",
    "        hY= selector.grid_scores_\n",
    "        H = pd.DataFrame(np.array([hX, hY]).T, columns = ['Number of parameters', 'Cross Validation Score'])\n",
    "\n",
    "        plt.figure()\n",
    "        plt.xlabel(\"Number of features selected\")\n",
    "        plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "        plt.plot(hX, hY)\n",
    "        plt.show()\n",
    "\n",
    "        return pd.DataFrame([selector.ranking_, selector.support_], columns = preprocessed_df.columns, index = ['Ranking', 'support'])\n",
    "\n",
    "    def make_skpot_var(self, param, temperature = 3, distribution = 'uniform', just_classifier = False): #'log-uniform'\n",
    "        value = self.export_kwards()[param]\n",
    "        if just_classifier == True: name = param.split('__')[1]\n",
    "        else: name = param\n",
    "\n",
    "        if value == 0 or value ==1: return\n",
    "\n",
    "        if type(value) == int:\n",
    "            if value == -1: return Integer(1, 200, name = name)\n",
    "            lower_bondary = int(value/temperature)\n",
    "            if lower_bondary < 2: lower_bondary = 2\n",
    "            upper_bondary = int(value*temperature) + lower_bondary\n",
    "            #if value <= 1: return Real(1e-3, 1, distribution ,name = name)\n",
    "            return Integer(lower_bondary, upper_bondary, distribution ,name = name)\n",
    "\n",
    "        if type(value) == float:\n",
    "            if value == -1: return Real(1, 200, name = name)\n",
    "            if value <= 1: return Real(1e-3, 1, distribution ,name = name)\n",
    "            lower_bondary = value/temperature\n",
    "            if lower_bondary < 2: lower_bondary = 2\n",
    "            upper_bondary = value*temperature + lower_bondary\n",
    "            return Real(lower_bondary, upper_bondary, distribution ,name = name)\n",
    "\n",
    "\n",
    "\n",
    "    def skopt_classifier_space(self, just_classifier = False):\n",
    "        dic = self.export_kwards()\n",
    "        classifier_params = [x for x in  dic.keys()\n",
    "                             if x.find('classifier__') != -1\n",
    "                             and  x.find('silent') == -1\n",
    "                             and  x.find('n_jobs') == -1\n",
    "                             and x.find('bagging_fraction') == -1\n",
    "                             and x != 'classifier__subsample'\n",
    "                             and x != 'classifier__validation_fraction'] # and\n",
    "        SPACE = [self.make_skpot_var(i, just_classifier = just_classifier) for i in classifier_params]\n",
    "        SPACE = [x for x in SPACE if x if x != None ]\n",
    "        return SPACE\n",
    "\n",
    "    def objective(self, params):\n",
    "        classifier = self.Pipe().set_params(**{dim.name: val for dim, val in zip(self.skopt_classifier_space(), params)})\n",
    "        return -np.mean(cross_val_score(classifier, self.df, self.df[self.TG], cv = StratifiedKFold(n_splits = 5, shuffle=True)))\n",
    "\n",
    "    def objective_just_classifier(self, params, metric , cv_method ):\n",
    "        return -np.mean(cross_val_score(self.cached_pipe['classifier'].set_params(**{dim.name: val for dim, val in zip(self.skopt_classifier_space(just_classifier = 1), params)}),\n",
    "                                        self.transformed_opt,\n",
    "                                        self.target_opt,\n",
    "                                        scoring = metric,\n",
    "                                        cv = cv_method,\n",
    "                                        n_jobs = -1))\n",
    "\n",
    "    def objective_cached(self, params):\n",
    "        return -np.mean(cross_val_score(self.cached_pipe.set_params(**{dim.name: val for dim, val in zip(self.skopt_classifier_space(), params)}),\n",
    "                                        self.df,\n",
    "                                        self.df[self.TG],\n",
    "                                        cv = StratifiedKFold(n_splits = 5, shuffle=True)))\n",
    "\n",
    "\n",
    "    def optimize_classifier(self, n_calls = 50, cache = False):\n",
    "        if cache:\n",
    "            self.Cache_pipe()\n",
    "            result = gp_minimize(self.objective_cached, self.skopt_classifier_space() , n_calls=n_calls)\n",
    "            self.release_cache()\n",
    "        else: result = gp_minimize(self.objective, self.skopt_classifier_space() , n_calls=n_calls)\n",
    "        #plot_convergence(result)\n",
    "        #_ = plot_objective(result, n_points=n_calls)\n",
    "        #print(result.fun)\n",
    "        return {'result': result, 'best_params': self.get_params(result, self.skopt_classifier_space() )}\n",
    "\n",
    "    def fast_optimize_classifier(self, n_calls = 50,  is_classifier = True):\n",
    "        self.Cache_pipe()\n",
    "\n",
    "        self.transformed_opt = self.cached_pipe['preprocessing'].fit_transform(self.df)\n",
    "        self.target_opt = self.df[self.TG]\n",
    "\n",
    "        if is_classifier:\n",
    "            cv_method = StratifiedKFold(n_splits = 5, shuffle=True)\n",
    "            metric    = 'f1_weighted'\n",
    "        else:\n",
    "            cv_method = KFold(n_splits = 5, shuffle=True)\n",
    "            metric    = 'r2'\n",
    "\n",
    "        result = gp_minimize(lambda x: self.objective_just_classifier(x, metric, cv_method), self.skopt_classifier_space(just_classifier = True) , n_calls=n_calls)\n",
    "        self.release_cache()\n",
    "\n",
    "        best_params = self.get_params(result, self.skopt_classifier_space(just_classifier = True))\n",
    "        best_params = {'classifier__'+ i[0]:i[1] for i in best_params.items()}\n",
    "\n",
    "        self.optimized_pipe = (self.Pipe().set_params(**best_params), 1)\n",
    "\n",
    "        return {'result': result, 'best_params':best_params}\n",
    "\n",
    "\n",
    "\n",
    "    def get_params(self, result_object, space):\n",
    "        try:\n",
    "            return { i.name: result_object.x[num] for  num, i in enumerate(space) }\n",
    "        except:\n",
    "            raise\n",
    "\n",
    "\n",
    "    def Vis_Cluster(self, method):\n",
    "        transformed = self.Pipe()['preprocessing'].fit_transform(self.df)\n",
    "        classsification = method.fit_predict(transformed)  #(*args, **kwds)\n",
    "        end_time = time.time()\n",
    "        palette = sns.color_palette('deep', np.unique(classsification).max() + 1)\n",
    "        colors = [palette[x] if x >= 0 else (0.0, 0.0, 0.0) for x in classsification]\n",
    "        plt.scatter(transformed.T[0], transformed.T[1], c=colors, s = MinMaxScaler(feature_range=(30, 300)).fit_transform(self.df[self.TG].values.reshape(-1, 1)) , **{'alpha' : 0.5,  'linewidths':0})\n",
    "        frame = plt.gca()\n",
    "        for num, spine in enumerate(frame.spines.values()):\n",
    "            if num == 1 or num == 3: spine.set_visible(False)\n",
    "        plt.title('Clusters found by {}'.format(str(method)), fontsize=24)\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "    def Evaluate_model(self):\n",
    "        tprs = []\n",
    "        aucs = []\n",
    "        prd = []\n",
    "        tru = []\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "        X = self.df.copy()\n",
    "        y = self.df[self.TG]\n",
    "        if self.optimized_pipe[1] == 0: clf = self.Pipe()\n",
    "        else: clf = self.optimized_pipe[0]\n",
    "        fig, ax = plt.subplots(1, 2, figsize = (20,10))\n",
    "        try:\n",
    "            for i, (train, test) in enumerate(StratifiedKFold(n_splits=5, shuffle=True).split(X, y)):\n",
    "                clf.fit(X.iloc[train], y.iloc[train])\n",
    "                viz = plot_roc_curve(clf, X.iloc[test], y.iloc[test],\n",
    "                                     name='ROC fold {}'.format(i),\n",
    "                                     alpha=0.3, lw=1, ax=ax[0])\n",
    "                interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "                interp_tpr[0] = 0.0\n",
    "                tprs.append(interp_tpr)\n",
    "                aucs.append(viz.roc_auc)\n",
    "\n",
    "            ax[0].plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "                    label='Chance', alpha=.8)\n",
    "\n",
    "            mean_tpr = np.mean(tprs, axis=0)\n",
    "            mean_tpr[-1] = 1.0\n",
    "            mean_auc = auc(mean_fpr, mean_tpr)\n",
    "            std_auc = np.std(aucs)\n",
    "            ax[0].plot(mean_fpr, mean_tpr, color='b',\n",
    "                    label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "                    lw=2, alpha=.8)\n",
    "\n",
    "            std_tpr = np.std(tprs, axis=0)\n",
    "            tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "            tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "            ax[0].fill_between(mean_fpr, tprs_lower, tprs_upper, color='steelblue', alpha=.2,\n",
    "                            label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "            ax[0].set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])\n",
    "            #       title=\"Receiver operating characteristic example\")\n",
    "            ax[0].legend(loc=\"lower right\")\n",
    "        except: print('non-binary classifier')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "        try:\n",
    "            plot_confusion_matrix(clf.fit(X_train, y_train), X_test, y_test,\n",
    "                                         display_labels=['negative detection', 'positive detection'],\n",
    "                                         cmap=plt.cm.Blues, ax = ax[1])\n",
    "            ax[1].grid(False)\n",
    "        except: print('is it a regressor?')\n",
    "        fig.tight_layout()\n",
    "        try:\n",
    "            report = classification_report(clf.predict(X_test), y_test, output_dict=True) # target_names=['Negative detection', 'Positive detection']\n",
    "        except: #### report for regression\n",
    "            if self.optimized_pipe[1] == 0: clf = self.Pipe()\n",
    "            else: clf = self.optimized_pipe[0]\n",
    "            report = cross_validate(clf, X, y, cv=5,  scoring=('neg_mean_absolute_percentage_error','r2','explained_variance', 'max_error', 'neg_mean_absolute_error', 'neg_mean_squared_error'))\n",
    "            fig, ax = plt.subplots(1, 1, figsize = (1,1))\n",
    "        return report, fig\n",
    "\n",
    "    def named_preprocessor(self):\n",
    "        naming_features = []\n",
    "        for transformer in self.Pipe()['preprocessing'].transformers:\n",
    "            transformed = ColumnTransformer(transformers = [transformer]).fit_transform(self.df)\n",
    "            if transformed.shape[1] == len(transformer[2]):\n",
    "                naming_features += list(transformer[2])\n",
    "            else:\n",
    "                naming_features += [transformer[0] +'__'+ str(i) for i in range(transformed.shape[1]) ]\n",
    "        if self.optimized_pipe[1] == 0: clf = self.Pipe()\n",
    "        else: clf = self.optimized_pipe[0]\n",
    "        return pd.DataFrame(clf['preprocessing'].fit_transform(self.df), columns = naming_features)\n",
    "\n",
    "    def Shapley_feature_importance(self):\n",
    "        if self.optimized_pipe[1] == 0: clf = self.Pipe()\n",
    "        else: clf = self.optimized_pipe[0]\n",
    "        shap.initjs()\n",
    "        dat_trans = self.named_preprocessor()\n",
    "        explainer = shap.TreeExplainer(clf['classifier'].fit(dat_trans, self.df[self.TG])) #,feature_perturbation = \"tree_path_dependent\"\n",
    "        shap_values = explainer.shap_values(dat_trans)\n",
    "\n",
    "        #### force-plot\n",
    "        a = [_force_plot_htmlsm(explainer.expected_value[i], shap_values[i], dat_trans) for i in len(shap_values)]\n",
    "\n",
    "        #### heatmap\n",
    "        #try: hmap = shap.TreeExplainer(clf['classifier'].fit(dat_trans, self.df[self.TG]), dat_trans) #redo check additivity\n",
    "        #except:\n",
    "        #    print('Failed in heatmap, using LGBMC instead')\n",
    "        #    hmap = shap.TreeExplainer(LGBMClassifier().fit(dat_trans, self.df[self.TG]), dat_trans)\n",
    "        #fig, ax = plt.subplots(1,1, figsize=(15, 15))\n",
    "        #shap.plots.heatmap(hmap(dat_trans)) ### figure is fig\n",
    "\n",
    "        ### dependence matrix\n",
    "        ivalues = explainer.shap_interaction_values(dat_trans)\n",
    "        figdm, axdm = plt.subplots(len( dat_trans.columns),  len(dat_trans.columns), figsize=(15, 15))\n",
    "        d = {i: name for i,name in enumerate(dat_trans.columns)}\n",
    "        for i in d.keys():\n",
    "            for j in d.keys():\n",
    "                shap.dependence_plot((d[i], d[j]), ivalues[1], dat_trans, ax = axdm[i,j], show = False)\n",
    "\n",
    "        ### dependence plots\n",
    "        #figdp, axdp = plt.subplots( len(dat_trans.columns)//4+1, 4, figsize=(15, 15))\n",
    "        #for num, col in enumerate(dat_trans.columns):\n",
    "        #    shap.dependence_plot(col, shap_values[1], dat_trans, ax = axdp[num//4,num%4], show= False)\n",
    "        return (a,  figdm) #fig,\n",
    "\n",
    "\n",
    "cyto.load_extra_layouts()\n",
    "height, width = [500,500]\n",
    "canvas_width = 500\n",
    "canvas_height = round(height * canvas_width / width)\n",
    "scale = canvas_width / width\n",
    "\n",
    "def plotly_cyt(d):\n",
    "    edges = [{'data': {'weight': i['data']['weight'], 'source': str(i['data']['source']), 'target': str(i['data']['target'])}}  for i in d['edges']]\n",
    "    nodes = [{'data': {k:i['data'][k] for k in ('id', 'value', 'name') }, 'position' : dict(zip(('x', 'y'),i['data']['data']))} for i in d['nodes']]\n",
    "    return nodes + edges\n",
    "\n",
    "def plotly_cyt2(G):\n",
    "    d = nx.cytoscape_data(G)['elements']\n",
    "    pos = nx.spring_layout(G)\n",
    "    edges = [{'data': {'weight': i['data']['weight'], 'source': str(i['data']['source']), 'target': str(i['data']['target'])}}  for i in d['edges']]\n",
    "    nodes = [{'data': {k:i['data'][k] for k in ('id', 'value', 'name') }, 'position' : dict(zip(('x', 'y'),j))} for i,j in zip(d['nodes'], list(pos.values()))]\n",
    "    return nodes + edges\n",
    "\n",
    "def plotly_cyt3(G):\n",
    "    d = nx.cytoscape_data(G)['elements']\n",
    "    pos = nx.spring_layout(G)\n",
    "    edges = [{'data': {'weight': i['data']['weight'], 'source': str(i['data']['source']), 'target': str(i['data']['target'])}}  for i in d['edges']]\n",
    "    nodes = [{'data': {**{k:i['data'][k] for k in ('id', 'value', 'name') }, **{'degree': degree[1]}} , 'position' : dict(zip(('x', 'y'),j))}\n",
    "             for i,j,degree in zip(d['nodes'], list(pos.values()), list(G.degree))]\n",
    "    return nodes + edges\n",
    "\n",
    "def make_colormap_clustering(column, palette, continuous, data):\n",
    "    if not continuous:\n",
    "        lut = dict(zip(sorted(data[column].unique()), sns.color_palette(palette, len(data[column].unique()))))\n",
    "    else: lut = sns.color_palette(palette, as_cmap=True)\n",
    "    return data[column].map(lut)\n",
    "\n",
    "\n",
    "def _force_plot_html(*args):\n",
    "    force_plot = shap.force_plot(*args, matplotlib=False, figsize=(18, 18))\n",
    "    shap_html = f\"<head>{shap.getjs()}</head><body>{force_plot.html()}</body>\"\n",
    "    return html.Iframe(srcDoc=shap_html, height='1800', width='1800',style={\"border\": 0})#\n",
    "\n",
    "def mplfig2html(figure):\n",
    "    pic_IObytes2 = io.BytesIO()\n",
    "    figure.savefig(pic_IObytes2,  format='png')\n",
    "    figure.clear()\n",
    "    pic_IObytes2.seek(0)\n",
    "    return  html.Img(src ='data:image/png;base64,{}'.format(base64.b64encode(pic_IObytes2.read()).decode()))\n",
    "\n",
    "def mpl2plotlyGraph(figure):\n",
    "    return dcc.Graph(ptools.mpl_to_plotly(figure)) #image_height: int=600,image_width: int=800\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec303cc-b3a1-4ccf-84a8-0ecce2c8f3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8097/\n"
     ]
    }
   ],
   "source": [
    "import scipy.spatial as sp, scipy.cluster.hierarchy as hc\n",
    "# Build App\n",
    "app = JupyterDash(__name__, external_stylesheets=[dbc.themes.MINTY]) #FLATLY, LUMEN, SUPERHERO\n",
    "\n",
    "def convert2cytoscapeJSON(G):\n",
    "    # load all nodes into nodes array\n",
    "    final = {}\n",
    "    final[\"nodes\"] = []\n",
    "    final[\"edges\"] = []\n",
    "    for node in G.nodes():\n",
    "        nx = {}\n",
    "        nx[\"data\"] = {}\n",
    "        nx[\"data\"][\"id\"] = node\n",
    "        nx[\"data\"][\"label\"] = node\n",
    "        final[\"nodes\"].append(nx.copy())\n",
    "    #load all edges to edges array\n",
    "    for edge in G.edges():\n",
    "        nx = {}\n",
    "        nx[\"data\"]={}\n",
    "        nx[\"data\"][\"id\"]=edge[0]+edge[1]\n",
    "        nx[\"data\"][\"source\"]=edge[0]\n",
    "        nx[\"data\"][\"target\"]=edge[1]\n",
    "        final[\"edges\"].append(nx)\n",
    "    return json.dumps(final)\n",
    "\n",
    "\n",
    "\n",
    "upload_tab = [\n",
    "    dbc.Row(dbc.Col(dbc.Jumbotron([\n",
    "        html.H1(\"Datafile\", className=\"display-3\"),\n",
    "        html.P('Acceptable formats are VCF and fasta. For fasta we expect consensus sequences metadata delimited by the \"|\" character, the first metadata column for the fasta files will be the one used. For VCF files we will use the SAMPLEs column to merge with the metadata',className=\"lead\",),\n",
    "        html.Hr(className=\"my-2\"),\n",
    "        #dbc.Row([\n",
    "        #dbc.Col(html.H4(\"Column of qPCR files to merge with habitat metadata:\") , width = 4),\n",
    "        #dbc.Col(dcc.Dropdown(options = [{\"label\": \"Sample\", \"value\": 'Sample'}] , value = 'Sample', id='qpcrdf', disabled = True), width = 3)]),\n",
    "        dcc.Upload(id='upload-qPCR2',children=html.Div(['Drag and Drop or ', html.A('Select Files')]),\n",
    "            style={'width': '100%',\n",
    "                'height': '120px',\n",
    "                'lineHeight': '120px',\n",
    "                'borderWidth': '2px',\n",
    "                'borderStyle': 'dashed',\n",
    "                'font-size': '20px',\n",
    "                'borderRadius': '5px',\n",
    "                'justify-content': 'center',\n",
    "                'textAlign': 'center',\n",
    "                'margin': '10px'}, multiple=False),\n",
    "        html.Div(id='qpcr-data-upload')  ]), width = 12),justify=\"center\",no_gutters=True),\n",
    "    dbc.Row(dbc.Col(dbc.Jumbotron([\n",
    "        html.H1(\"Additional metadata\", className=\"display-3\"),\n",
    "        html.P(' Metadata is expected to be a csv file. Merging of the metadata and sequence file will occur on the intersection chosen column of the metadata file and the ID column from the datafile. Unmatching IDs from Data and Metadata files will be discarded.',className=\"lead\",),\n",
    "        html.Hr(className=\"my-2\"),\n",
    "        dbc.Row([\n",
    "        dbc.Col(html.H4(\"Column of metadata file to merge:\") , width = 4),\n",
    "        dbc.Col(dcc.Dropdown(id='habitatdf'), width = 3)]),\n",
    "        dcc.Upload(id='upload-habitat',children=html.Div(['Drag and Drop or ', html.A('Select Files')]),\n",
    "            style={'width': '100%',\n",
    "                'height': '120px',\n",
    "                'lineHeight': '120px',\n",
    "                'borderWidth': '2px',\n",
    "                'borderStyle': 'dashed',\n",
    "                'borderRadius': '5px',\n",
    "                'font-size': '20px',\n",
    "                'justify-content': 'center',\n",
    "                'textAlign': 'center',\n",
    "                'margin': '10px'},multiple=True),\n",
    "        html.Div(id='habitat-data-upload') ]), width = 12),justify=\"center\",no_gutters=True),\n",
    "    \n",
    "    dbc.Row(dbc.Col(dbc.Jumbotron([\n",
    "        html.H1(\"Send complete dataset directly\", className=\"display-3\"),\n",
    "        dcc.Upload(id='upload_dataset_directly',children=html.Div(['Drag and Drop or ', html.A('Select Files')]),\n",
    "        style={'width': '100%', 'height': '120px',  'lineHeight': '120px', 'font-size': '20px',   'borderWidth': '2px', 'borderStyle': 'dashed',  'borderRadius': '5px',   'textAlign': 'center', 'margin': '10px'},multiple=False),\n",
    "        html.Div(id='direct_dataframe_upload_name')\n",
    "    ]), width = 12),justify=\"center\",no_gutters=True)    \n",
    "]\n",
    "\n",
    "merge_tab = [\n",
    "    dbc.Jumbotron([\n",
    "        html.H1(\"Merged dataset overview \", className=\"display-3\"),\n",
    "        html.P('Look for parameters that have unexpected behavior, dataset size and other possible concerns with data integrity',className=\"lead\",),\n",
    "        html.Hr(className=\"my-2\"),html.P(\"\"),\n",
    "        dcc.Loading(id=\"loading-1\",type=\"default\", children=html.Div(id='Merged_df', style = {'justify-content': 'center', 'margin': '0 auto', 'width': '90%'} ) )\n",
    "    ]),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "VIS = [dbc.Row(dbc.Col(html.Div( id = 'keplermap', style = {'overflow': 'hidden'}), width=\"100%\",style = {'overflow': 'clip'}), no_gutters=True,justify=\"center\", style = {'overflow': 'hidden'}),]\n",
    "kep_tab=[ dbc.Row([\n",
    "           dbc.Col(\n",
    "               [dbc.Row([\n",
    "                   dbc.Jumbotron([\n",
    "                       html.H4(\"what are the continous columns for the UMAP?\", id = 'kep_tab_continuous_columns_target'),\n",
    "                       dbc.Popover([ dbc.PopoverHeader(\"how we look at continuous data\"),dbc.PopoverBody(\"https://umap-learn.readthedocs.io/en/latest/basic_usage.html\")],target=\"kep_tab_continuous_columns_target\",trigger=\"hover\",),\n",
    "                       dcc.Dropdown(options=[],value=[], multi=True, id = 'UMAP_cont'),\n",
    "                       html.H4(\"what are the categorical columns for the UMAP?\", id = 'kep_tab_cat_columns_target'),\n",
    "                       dbc.Popover([ dbc.PopoverHeader(\"how we look at categorical data\"),dbc.PopoverBody(\"see https://umap-learn.readthedocs.io/en/latest/composing_models.html#diamonds-dataset-example\")],target=\"kep_tab_cat_columns_target\",trigger=\"hover\",),\n",
    "                       dcc.Dropdown(options=[],value=[], multi=True, id = 'UMAP_cat'),\n",
    "                       html.H4(\"Do you want to fit the UMAP to a feature?\", id = 'keep_tab_metric_learn'), #https://umap-learn.readthedocs.io/en/latest/supervised.html\n",
    "                       dbc.Popover([ dbc.PopoverHeader(\"fitting umap to feature\"),dbc.PopoverBody(\"https://umap-learn.readthedocs.io/en/latest/supervised.html\")],target=\"keep_tab_metric_learn\",trigger=\"hover\",),\n",
    "                       dcc.Dropdown(options=[],value=[], multi=False, id = 'UMAP_y'),\n",
    "                       html.H4(\"How many neighboors for the UMAP to use?\", id = 'keep_tab_nneighboors'),\n",
    "                       dbc.Popover([ dbc.PopoverHeader(\"n neighboors parameter\"),dbc.PopoverBody(\"This parameter controls how UMAP balances local versus global structure in the data. It does this by \\\n",
    "                       constraining the size of the local neighborhood UMAP will look at when attempting to learn the manifold structure of the data. \\\n",
    "                       This means that low values of n_neighbors will force UMAP to concentrate on very local structure (potentially to the detriment of the big picture),\\\n",
    "                       while large values will push UMAP to look at larger neighborhoods of each point when estimating the manifold structure of the data, \\\n",
    "                       losing fine detail structure for the sake of getting the broader of the data. _ see https://umap-learn.readthedocs.io/en/latest/parameters.html#n-neighbors\")],target=\"keep_tab_nneighboors\",trigger=\"hover\",),\n",
    "                       dbc.Input(id=\"n_neighboors\", type=\"number\", value = 15, min = 10, max = 1000), #https://umap-learn.readthedocs.io/en/latest/parameters.html#n-neighbors\n",
    "                       html.H4('Type of scaling to use:', id= 'kep_tab_scale'),\n",
    "                       dbc.Popover([ dbc.PopoverHeader(\"Should I scale my data?\"),dbc.PopoverBody(\"The default answer is yes, but, of course, the real answer is “it depends”. \\\n",
    "                       If your features have meaningful relationships with one another (say, latitude and longitude values) then normalising per feature is not a good idea. \\\n",
    "                       For features that are essentially independent it does make sense to get all the features on (relatively) the same scale. \\\n",
    "                       The best way to do this is to use pre-processing tools from scikit-learn. All the advice given there applies as sensible preprocessing for UMAP,\\\n",
    "                       and since UMAP is scikit-learn compatible you can put all of this together into a scikit-learn pipeline.\")],target=\"kep_tab_scale\",trigger=\"hover\",),\n",
    "                       dbc.RadioItems(id=\"UMAP_radio\",\n",
    "                        options=[\n",
    "                            {\"label\": \"No Standardization\", \"value\": 1},\n",
    "                            {\"label\": \"Standard scaler\", \"value\": 2},\n",
    "                            {\"label\": \"Pipeline from machine learning tab\",\"value\": 3}],value = 2,\n",
    "                            labelCheckedStyle={\"color\": \"#223c4f\", 'font-size': '18px'},\n",
    "                            labelStyle = {}, style = {'font-size': '18px', 'margin' : '10px', 'margin-left': '60px' ,'transform':'scale(1.2)'}, switch=True,\n",
    "                            inputStyle = { }\n",
    "                                     ),\n",
    "                      dbc.Button(\"Generate UMAP\", color=\"info\", size = 'lg', className=\"mr-1\", block=True, id='UMAP_start') ]),\n",
    "                      dbc.Popover([ dbc.PopoverHeader(\"what is UMAP?\"),dbc.PopoverBody(\"see https://umap-learn.readthedocs.io/en/latest/how_umap_works.html \\nhttps://umap-learn.readthedocs.io/en/latest/scientific_papers.html\\nhttps://umap-learn.readthedocs.io/en/latest/faq.html#what-is-the-difference-between-pca-umap-vaes\")],target=\"UMAP_start\",trigger=\"hover\",),\n",
    "\n",
    "\n",
    "               ])],width=2)  ,\n",
    "           dbc.Col([dcc.Loading(id=\"loading-umap\",type=\"default\", children= dcc.Tabs([\n",
    "               dcc.Tab(label = 'umap-view', children = [html.Div(dcc.Graph(id='UMAP_view'), style = {'height': '1200px', 'width' : '1500px','margin-left':'30px'}),html.Div( id = 'umap_selected_stats', style = {'width': '98%'})] ),\n",
    "               dcc.Tab(label = 'heatmap/cytoscape', children = html.Div( id = 'cytoscape', style = {'justify-content': 'center'} )),\n",
    "               dcc.Tab(label = 'hdbscan clustering', children = html.Div(id='graph') ),\n",
    "\n",
    "           ], style = {'justify-content': 'center', 'width': '100%','margin-left': '12px','overflow': 'clip'})) ], width=10, style = {'overflow': 'clip'})],  no_gutters=True)] #\n",
    "\n",
    "#className=\"nav nav-pills\"      , no_gutters=True         autosize=False\n",
    "\n",
    "time_series_tab = [\n",
    "    dbc.Row([\n",
    "        dbc.Col( dbc.Jumbotron([\n",
    "            html.H4(\"Target column\"),\n",
    "            dcc.Dropdown(options=[],value=[], multi=False, id = 'prophet_y'),\n",
    "            html.H4(\"Datetime column\"),\n",
    "            dcc.Dropdown(options=[],value=[], multi=False, id = 'prophet_ds'),\n",
    "            html.Hr(style= {'margin-bottom': '25px'}),\n",
    "            html.H4(\"Additional regressors\"),\n",
    "            dcc.Dropdown(options=[],value=[], multi=True, id = 'prophet_regressors'),\n",
    "            html.Hr(style= {'margin-bottom': '25px'}),\n",
    "            html.H4('Rolling average'),\n",
    "            html.H5('number of days'),\n",
    "            dbc.Input(id=\"prophet_rolling_average\", type=\"number\", value = 0, min = 0, max = 366, step = 0.25),\n",
    "            html.Hr(style= {'margin-bottom': '25px'}),\n",
    "            html.H4(\"Growth\"),\n",
    "            dcc.Dropdown(options=[\n",
    "                {\"label\": \"logistic\", \"value\": 'logistic'},\n",
    "                {\"label\": \"flat\", \"value\": 'flat'},\n",
    "                {\"label\": \"linear\", \"value\": 'linear'}\n",
    "            ],value='linear', multi=False,id = 'prophet_growth'),\n",
    "            html.H4(\"Target maximum value\"),\n",
    "            dbc.Input(id=\"prophet_cap\", type=\"number\", value = 1, step = .01),\n",
    "            html.H4(\"Target minimum value\"),\n",
    "            dbc.Input(id=\"prophet_floor\", type=\"number\", value = 0, step = .01),\n",
    "            html.Hr(style= {'margin-bottom': '25px'}),\n",
    "            html.H4('Seasonnality'),\n",
    "            html.H5('frequency'),\n",
    "            dbc.Checklist( options = [\n",
    "                {\"label\": \"Yearly\", \"value\": 'yearly_seasonality'},\n",
    "                {\"label\": \"Weekly\", \"value\": 'weekly_seasonality'},\n",
    "                {\"label\": \"Daily\", \"value\": 'daily_seasonality'},\n",
    "            ]  ,value=['yearly_seasonality'], id = 'prophet_seasonality' ,\n",
    "                          style = {'font-size': '18px', 'margin' : '10px', 'margin-left': '60px' ,'transform':'scale(1.2)'}, switch=True ),\n",
    "            html.H5('mode'),\n",
    "            dcc.Dropdown(options=[\n",
    "                {\"label\": \"additive\", \"value\": 'additive'},\n",
    "                {\"label\": \"multiplicative\", \"value\": 'multiplicative'}\n",
    "            ], multi=False,id = 'seasonality_mode', value = 'additive'),\n",
    "            html.H5('scale'),\n",
    "            dbc.Input(id=\"season_prior\", type=\"number\", value = 10, min = 1, max = 100),\n",
    "            html.Hr(style= {'margin-bottom': '25px'}),\n",
    "            html.H4('Change points'),\n",
    "            html.H5('quantity'),\n",
    "            dbc.Input(id=\"prophet_n_change_points\", type=\"number\", value = 25, min = 0, max = 100,step =1),\n",
    "            html.H5('scale'),\n",
    "            dbc.Input(id=\"changepoint_prior\", type=\"number\", value = .05, min = 0, max = 10., step = 0.01),\n",
    "            html.H5('range'),\n",
    "            dbc.Input(id=\"changepoint_range\", type=\"number\", value = .8, min = 0.1, max = 1., step = 0.01),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ]), width = 2),\n",
    "        dbc.Col(dcc.Loading(id=\"loading-prophet\",type=\"default\", children=html.Div(id='prophet_plots', style = {'justify-content': 'center', 'margin': '0 auto', 'width': '100%'} ), style= {'margin-top': '100px'})),\n",
    "        dbc.Col( dbc.Jumbotron([\n",
    "            html.H4('Forecast'),\n",
    "            html.H5('prediction range'),\n",
    "            dcc.DatePickerRange(id= 'prophet_future_dates', display_format='MMM DD YYYY'),\n",
    "            html.Hr(style= {'margin-bottom': '50px'}),\n",
    "            html.H5('remove these month'),\n",
    "            dcc.Dropdown(options=[ {\"label\":  calendar.month_name[num], \"value\": num} for num in range(1,12)],value=[], multi=True,id = 'prophet_remove_months'),\n",
    "            html.H5('remove these days of the week'),\n",
    "            dcc.Dropdown(options=[ {\"label\":  day_name, \"value\": num} for num,day_name in enumerate(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])],\n",
    "                         value=[], multi=True,id = 'prophet_remove_days_of_the_week'),\n",
    "            html.H5('remove these hours of the day'),\n",
    "            dcc.Dropdown(options=[ {\"label\":  str(num)+':00-'+str(num+1)+':00', \"value\": num} for num in range(0,24)],value=[], multi=True,id = 'prophet_remove_hours'),\n",
    "            html.Hr(style= {'margin-bottom': '70px'}),\n",
    "            dbc.Button(\"Run forecast\", color=\"info\", size = 'lg', className=\"mr-1\", block=True, id='run_prophet')\n",
    "        ]) , width = 2)\n",
    "\n",
    "\n",
    "    ], no_gutters=True, style={'margin-bottom': '10px'})\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "transformers = [x for x in sklearn.preprocessing.__all__ + ['UMAP'] + sklearn.decomposition.__all__ + sklearn.manifold.__all__  if x[0].isupper() and x != 'SparseCoder'] + ['passthrough']\n",
    "transformer_options = [ {'label': x, 'value': x } for x in  transformers] # eval(x+ '()')\n",
    "\n",
    "ML_tab = [\n",
    "   dbc.Row([\n",
    "       dbc.Col(\n",
    "           [dbc.Jumbotron([\n",
    "                dbc.Row([\n",
    "                   dbc.Col([ html.H4(\"number of transformers:\")]),\n",
    "                   dbc.Col([#dcc.Dropdown(options=[ {'label': str(x), 'value': str(x)} for x in range(10)],value='2', multi=False,clearable=False, id = 'n_tabs')\n",
    "                            dbc.Input(id=\"n_tabs\", type=\"number\", value = 2, min = 1, max = 10)\n",
    "                           ]),\n",
    "                   dbc.Col([html.H4(\"Target:\")]),\n",
    "                   dbc.Col([dcc.Dropdown(options=[],value=[], multi=False, id = 'ML_target',clearable=False)]),\n",
    "                   dbc.Col([html.H4(\"Classifier:\", id = 'ml_tab_classifier'), dbc.Popover([ dbc.PopoverHeader(\"chosing a classifier\"),dbc.PopoverBody('see: \\\n",
    "                   https://scikit-learn.org/stable/supervised_learning.html#supervised-learning\\n https://lightgbm.readthedocs.io/en/latest/Quick-Start.html ')],target=\"ml_tab_classifier\",trigger=\"hover\",)]),\n",
    "                   dbc.Col([dcc.Dropdown(options=[ {'label': x, 'value': x} for x in  ['LGBMClassifier', 'LGBMRegressor']  + sklearn.ensemble.__all__ + sklearn.linear_model.__all__]\n",
    "                               ,value = 'RandomForestClassifier',  multi=False, id = 'clf_disp', clearable=False)]) ])]),\n",
    "            dbc.Jumbotron([dbc.Row([dbc.Col(\n",
    "                   [html.H4(\"Columns to be transformed:\")] +\n",
    "                   [ dcc.Dropdown(options= ['0'], value = ['0'],multi=True,clearable=False, id = 'Columns_'+ str(i))  for i in range(3)], id = 'preprocessing_columns'),\n",
    "            dbc.Col(\n",
    "                   [html.H4(\"Column transformers:\", id = 'ml_tab_column_trans')] + #https://scikit-learn.org/stable/modules/preprocessing.html#\n",
    "                   [ dcc.Dropdown(options= transformer_options, value = ['passthrough'], multi=True,clearable=False, id = 'ColumnTransformer_'+ str(i))  for i in range(3)], id = 'preprocessing_functions'),\n",
    "            dbc.Popover([ dbc.PopoverHeader(\"preprocessing the data\"),dbc.PopoverBody(\"see:\\n https://scikit-learn.org/stable/modules/preprocessing.html\\n\\\n",
    "                   https://scikit-learn.org/stable/modules/decomposition.html#decompositions#\\nhttps://scikit-learn.org/stable/modules/clustering.html#clustering\")],target=\"ml_tab_column_trans\",trigger=\"hover\",)\n",
    "                                   ])])\n",
    "\n",
    "\n",
    "           ],width=6, id='ml_user_input'), ] + [dbc.Col([dbc.Button(\"Update Pipeline\", color=\"info\", size = 'lg', className=\"mr-1\", block=True, id='submit_pipe'),\n",
    "                                                         html.Div(id = 'show_pipeline', style ={'width': '50%','borderWidth': '0px' ,'border': 'white'})], width = 6)], no_gutters=True,justify=\"center\"),\n",
    "    dbc.Row([dbc.Col(\n",
    "        dbc.Jumbotron([\n",
    "           dbc.Row([ html.H1(\"Testing the pipeline\", style ={'margin': '20px'})]), #,justify=\"center\"\n",
    "            dbc.Row([dbc.Col([html.H4(\"Number of runs for hyperparameter optimization:\", id = 'ml_tab_tunning')], width = 3),\n",
    "                      dbc.Popover([ dbc.PopoverHeader(\"Tunning the model\"),dbc.PopoverBody(\"here we use scikit optimize's bayesian optimization to tune the hyperparameters\\\n",
    "                      https://scikit-optimize.github.io/stable/auto_examples/bayesian-optimization.html\")],target=\"ml_tab_tunning\",trigger=\"hover\",),\n",
    "                    dbc.Col([dbc.Input(id=\"slider_hyperopt\", type=\"number\", value = 50, min = 10, max = 1000)], width = 1)], no_gutters=True, style={'margin-bottom': '10px'}), #\n",
    "            dbc.Row([dbc.Button(\"Run pipeline\", color=\"info\", size = 'lg', className=\"mr-1\", block=True, id='run_ML')]),\n",
    "            dcc.Loading(id=\"loading-ml\",type=\"default\", children=html.Div(id = 'ml_results', style = {'justify-content': 'center', 'margin': '0 auto', 'width': '2200', 'height' : '1400px'}),\n",
    "                                 style= {'margin-top': '-300px','justify-content': 'center'})])\n",
    "                     , width = 12,  style = {'justify-content': 'center', 'height' : '2000px'}) ], no_gutters=True)\n",
    "]\n",
    "\n",
    "\n",
    "# html.Iframe(srcDoc = ret_map._repr_html_().decode(), height='1280', width='2350') iframe for html representation of pipeline sklearn\n",
    "tab_style = {\n",
    "    \"background\": \"#223c4f\",\n",
    "    'color': \"#6cc3d5\",\n",
    "    'text-transform': 'lowercase',\n",
    "    'border': '#223c4f',\n",
    "    'font-size': '12px',\n",
    "    'font-weight': 200,\n",
    "    'align-items': 'center',\n",
    "    'justify-content': 'center',\n",
    "    'border-radius': '0px',\n",
    "    #'padding':'6px'\n",
    "}\n",
    "\n",
    "tab_selected_style = {\n",
    "    \"background\": \"#153751\",\n",
    "    'color': 'white',\n",
    "    'text-transform': 'uppercase',\n",
    "    'font-size': '12px',\n",
    "    'font-weight': 200,\n",
    "    'align-items': 'center',\n",
    "    'justify-content': 'center',\n",
    "    #'box-shadow': '60px 0 #223c4f, -60px 0 solid #223c4f',\n",
    "    'border-style': 'solid #223c4f',\n",
    "    'border-color': '#223c4f',\n",
    "    'border-width': '0',\n",
    "    #'border-radius': '50px'\n",
    "}\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dbc.NavbarSimple([], brand = 'Sars-Cov-2 genome viewer', brand_style ={'color': \"white\",'font-size': '14px'} ,\n",
    "                     style = { 'align-items': 'left','justify-content': 'left', 'font-size': '14px', 'height': '40px'},\n",
    "                    color = \"#223c4f\"),\n",
    "    dcc.Store(id='all_qPCR_concat', storage_type='memory'), #storage_type='local'\n",
    "    dcc.Store(id='habitatcsv', storage_type='memory'),  #df_with_umap\n",
    "    dcc.Store(id='df', storage_type='memory'),\n",
    "    dcc.Store(id='df_with_umap', storage_type='memory'),\n",
    "    dcc.Store(id='umap_select_columns', storage_type='memory'),\n",
    "    dcc.Store(id='selected_points_umap', storage_type='memory'), #html.Table(id='all_dfs')    selected_points_umap\n",
    "    dcc.Tabs([\n",
    "        dcc.Tab(label = 'Dataset', children = upload_tab , style=tab_style, selected_style=tab_selected_style),\n",
    "        dcc.Tab(label = 'Quality Control', children = merge_tab , style=tab_style, selected_style=tab_selected_style), \n",
    "        dcc.Tab(label = 'Genome viewer', children = genome_viewer , style=tab_style, selected_style=tab_selected_style),\n",
    "        dcc.Tab(label='Exploratory Data Analysis', children=kep_tab, style=tab_style, selected_style=tab_selected_style),\n",
    "        dcc.Tab(label='Geoposition', children=VIS, style=tab_style, selected_style=tab_selected_style),\n",
    "        dcc.Tab(label='Time Series', children=time_series_tab, style=tab_style, selected_style=tab_selected_style),\n",
    "        dcc.Tab(label='Machine Learning', children=ML_tab, style=tab_style, selected_style=tab_selected_style)],className=\"nav nav-pills\") ,\n",
    "        ])\n",
    "\n",
    "\n",
    "cyto.load_extra_layouts()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def inpt_children_to_pipe(columns, funcs, classif):\n",
    "    C = [x['props']['value'] for x in columns[1:]]\n",
    "    F = [x['props']['value'] for x in funcs[1:]]\n",
    "    if classif == 'LGBMClassifier':\n",
    "         return Pipeline(steps = [('preprocessing', make_pipe(C, F)), ('classifier', eval(classif + \"(boosting_type='gbdt',  subsample=1.0)\") )]) #boosting_type='gbdt', bagging_fraction = 0\n",
    "    return Pipeline(steps = [('preprocessing', make_pipe(C, F)), ('classifier', eval(classif + '()') )])\n",
    "\n",
    "\n",
    "def make_pipe(columns_list, transformer_list):\n",
    "    simplfy = []\n",
    "    for num, (cols, trans) in enumerate(zip(columns_list, transformer_list) ):\n",
    "        sub_smp = []\n",
    "        for x in trans:\n",
    "            if x[0].isupper() == True:\n",
    "                if x == 'PCA': sub_smp += [PCA(n_components = 2)]\n",
    "                else: sub_smp += [eval(x+ '()')]\n",
    "            else: sub_smp += [x]\n",
    "        simplfy += [tuple([str(num), make_pipeline(*sub_smp), tuple(cols)])]\n",
    "    return ColumnTransformer(simplfy)\n",
    "    #simplfy =[ tuple([str(num), make_pipeline(*[eval(x+ '()') if x[0].isupper() == True else x for x in trans ]), tuple(cols)]) for num, (cols, trans) in enumerate(zip(columns_list, transformer_list) )]\n",
    "    #return ColumnTransformer(simplfy)\n",
    "\n",
    "\n",
    "@app.callback(Output(component_id= 'ml_results', component_property ='children'),\n",
    "              Input(component_id = 'run_ML', component_property = 'n_clicks'),\n",
    "              State(component_id= 'preprocessing_functions', component_property ='children'),\n",
    "              State(component_id= 'preprocessing_columns', component_property ='children'),\n",
    "              State(component_id = 'clf_disp', component_property = 'value'),\n",
    "              State(component_id = 'df', component_property = 'data'),\n",
    "              State(component_id = 'ML_target', component_property = 'value'),\n",
    "             State(component_id = 'slider_hyperopt', component_property = 'value'))\n",
    "def run_ML(clicked, f_list, c_list, val, data, target, ncalls):\n",
    "    pipe = inpt_children_to_pipe(c_list,f_list, val)\n",
    "    try: df = pd.read_json(data,convert_dates = False)\n",
    "    except: return html.Div()\n",
    "    Maj = pipemaker2(df, pipe, target)\n",
    "    try:\n",
    "        opt_results = Maj.fast_optimize_classifier(n_calls= int(ncalls))\n",
    "        new_pipe2 = [html.Iframe(srcDoc = estimator_html_repr(Maj.optimized_pipe[0]), height='450', width='1150', hidden = 'hidden')]\n",
    "    except:\n",
    "        try:\n",
    "            opt_results = Maj.fast_optimize_classifier(n_calls= int(ncalls), is_classifier= False)\n",
    "            new_pipe2 = [html.Iframe(srcDoc = estimator_html_repr(Maj.optimized_pipe[0]), height='450', width='1150', hidden = 'hidden')]\n",
    "        except:\n",
    "            new_pipe2 = [html.Iframe(srcDoc = estimator_html_repr(Maj.Pipe()), height='450', width='1150', hidden = 'hidden')]\n",
    "            Maj = pipemaker2(pd.read_json(data,convert_dates = False), inpt_children_to_pipe(c_list,f_list, val), target)\n",
    "    try:\n",
    "        scores, fig  = Maj.Evaluate_model()\n",
    "        rev_table = pd.DataFrame(scores).T.reset_index()\n",
    "        graph_part = mplfig2html(fig)\n",
    "        scoreshtml = [dash_table.DataTable( data=rev_table.to_dict('records'), columns=[{'name': str(i), 'id': str(i)} for i in rev_table.columns], style_table={'overflowX': 'auto'},\n",
    "                                                      style_cell={'minWidth': '180px', 'width': '180px', 'maxWidth': '180px','overflow': 'hidden','textOverflow': 'ellipsis'}),graph_part]\n",
    "\n",
    "\n",
    "    except: scoreshtml =  [html.H3('Failed evaluate scores: is it a regressor?', className=\"display-3\") ]\n",
    "\n",
    "\n",
    "\n",
    "    #fplot,  fig2 = Maj.Shapley_feature_importance() #fig1,\n",
    "\n",
    "    ##### shapley graphs\n",
    "    if Maj.optimized_pipe[1] == 0: clf = Maj.Pipe()\n",
    "    else: clf = Maj.optimized_pipe[0]\n",
    "\n",
    "    new_pipe = html.Iframe(srcDoc = estimator_html_repr(clf), height='450', width='1150', hidden = True)\n",
    "    #fig, ax = plt.subplots(figsize=(15, 15))\n",
    "    shap.initjs()\n",
    "    dat_trans = Maj.named_preprocessor()\n",
    "    try:\n",
    "        explainer = shap.TreeExplainer(clf['classifier'].fit(dat_trans, Maj.df[Maj.TG]), dat_trans) ######## added dat_trans here ____________________remove if breaks!!!\n",
    "        shap_values = explainer.shap_values(dat_trans, check_additivity=False)        #,feature_perturbation = \"tree_path_dependent\"\n",
    "    except:\n",
    "        explainer = shap.Explainer(clf['classifier'].fit(dat_trans, Maj.df[Maj.TG]), dat_trans)\n",
    "        shap_values = explainer.shap_values(dat_trans)\n",
    "\n",
    "    #### summary plot\n",
    "    fig_summary, ax = plt.subplots(figsize=(15, 15))\n",
    "    shap.summary_plot(shap_values,dat_trans, plot_type='bar',plot_size=(10,10), max_display=20,show= False)\n",
    "    sumhtml = [mplfig2html(fig_summary)]\n",
    "\n",
    "    #### force-plot\n",
    "    try: a = [_force_plot_html(explainer.expected_value[i], shap_values[i], dat_trans) for i in range(len(shap_values))]\n",
    "    except: a = [_force_plot_html(explainer.expected_value, shap_values, dat_trans) ]\n",
    "    ### dependence matrix\n",
    "    try:\n",
    "        ivalues = shap.TreeExplainer(clf['classifier'].fit(dat_trans, Maj.df[Maj.TG])).shap_interaction_values(dat_trans)\n",
    "        figdm, axdm = plt.subplots(len( dat_trans.columns),  len(dat_trans.columns), figsize=(15, 15))\n",
    "        #d = {i: name for i,name in enumerate(dat_trans.columns)}\n",
    "        #for i in d.keys():\n",
    "        #    for j in d.keys():\n",
    "        #        shap.dependence_plot((d[i], d[j]), ivalues, dat_trans, ax = axdm[i,j], show = False)\n",
    "        #fig2html = mplfig2html(figdm)\n",
    "        shap.summary_plot(ivalues, dat_trans, show= False)\n",
    "        ####erase here if necessary\n",
    "        figdm = plt.gcf()\n",
    "        figdm.set_figheight(15)\n",
    "        figdm.set_figwidth(15)\n",
    "        figdm.tight_layout()\n",
    "        fig2html = mplfig2html(figdm)\n",
    "    except:\n",
    "        fig2html = html.H5(\"Shapley interaction matrix only available for tree-based models\")\n",
    "\n",
    "    #### heatmap\n",
    "    try:\n",
    "        try : shap.plots.heatmap(explainer(dat_trans), show= False)\n",
    "        except : shap.plots.heatmap(explainer(dat_trans), show= False, check_additivity=False)\n",
    "        fig1 = plt.gcf()\n",
    "        fig1.set_figheight(15)\n",
    "        fig1.set_figwidth(15)\n",
    "        fig1.tight_layout()\n",
    "        fig1html = mplfig2html(fig1)\n",
    "        #fig1_1, ax = plt.subplots(1,1, figsize=(15, 15))\n",
    "        #shap.plots.bar(hmap(dat_trans, check_additivity=False), show = False)\n",
    "        #fig1_1 = plt.gcf()\n",
    "        #fig1_1.set_figheight(10)\n",
    "        #fig1_1.set_figwidth(10)\n",
    "        #fig1_1html = mplfig2html(fig1_1)\n",
    "        heatmapfigs = [fig1html]\n",
    "    except:\n",
    "        heatmapfigs = [html.H5('heatmap is only available in binary classification')]\n",
    "\n",
    "    if val == \"LGBMClassifier\" or val == 'LGBMRegressor':\n",
    "        decision_tree, ax = plt.subplots(1,1, figsize=(15, 15))\n",
    "        plot_tree(clf['classifier'], ax=ax, show_info = ['leaf_count','data_percentage','internal_value', 'internal_weight', 'split_gain'])\n",
    "        lgbmfig = [mplfig2html(decision_tree)]\n",
    "    else:\n",
    "        lgbmfig = []\n",
    "\n",
    "\n",
    "    figure_names = ['scores', 'roc-auc & cm', 'feature importance'] + ['force-plot feat'+ str(i) for i in range(len(a))] + ['heatmap', 'feature interaction'] + ['decision_tree' for x in lgbmfig]\n",
    "    ml_all_figures = scoreshtml+ sumhtml +a +heatmapfigs + [fig2html] + lgbmfig\n",
    "    ml_result_tabs = dcc.Tabs([dcc.Tab(children = html.Div(content, style = {'justify-content': 'center', 'margin': '0 auto', 'width': '2200px', 'height' : '1400px'}), label = name) for name,content in zip(figure_names, ml_all_figures)], style = {'justify-content': 'center', 'margin': '0 auto', 'width': '100%'})\n",
    "\n",
    "    return [ml_result_tabs]+ new_pipe2\n",
    "    #return dbc.Jumbotron(scoreshtml+ sumhtml +a +heatmapfigs + [fig2html]+ new_pipe2)#+ new_pipe2 #fig1html,fig2html\n",
    "    #html.Div(id = 'ml_results', style = {'justify-content': 'center', 'margin': '0 auto', 'width': '2200px', 'height' : '1500px'}\n",
    "\n",
    "@app.callback(Output(component_id= 'show_pipeline', component_property ='children'),\n",
    "              Input(component_id= 'preprocessing_functions', component_property ='children'),\n",
    "              Input(component_id= 'preprocessing_columns', component_property ='children'),\n",
    "              Input(component_id = 'clf_disp', component_property = 'value'),\n",
    "              Input(component_id= 'ml_results', component_property ='children'),\n",
    "              Input(component_id = 'submit_pipe', component_property = 'n_clicks') )\n",
    "def html_pipe(f_list, c_list, val, ml_children, clicked):\n",
    "    ctx = dash.callback_context.triggered[0]['prop_id'].split('.')[0]\n",
    "    if ctx != 'ml_results':\n",
    "        pipe = inpt_children_to_pipe(c_list,f_list, val)\n",
    "        return html.Iframe(srcDoc = estimator_html_repr(pipe), height='450', width='1150',style = {'border-style':'none', 'frameborder':'none'})\n",
    "    else:\n",
    "        try: ret = ml_children[-1]['props']['srcDoc']#####['props']['children'][-1]['props']['srcDoc']\n",
    "        except: return html.Iframe(srcDoc = estimator_html_repr(inpt_children_to_pipe(c_list,f_list, val)), height='450', width='1150',  style = {'border-style':'none', 'frameborder':'none'})\n",
    "    return html.Iframe(srcDoc = ret, height='450', width='1150', style = {'border-style':'none', 'frameborder':'none'}) #1150\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(Output(component_id= 'preprocessing_functions', component_property ='children'),\n",
    "              Output(component_id= 'preprocessing_columns', component_property ='children'),\n",
    "              Input('n_tabs', 'value'),\n",
    "              Input(component_id = 'df', component_property = 'data'),\n",
    "              State(component_id= 'preprocessing_functions', component_property ='children'),\n",
    "              State(component_id= 'preprocessing_columns', component_property ='children') )\n",
    "def reajust_number_of_column_transformers_ML(val,data,oldf, oldc ):\n",
    "    if int(val) > len(oldf) - 1 :\n",
    "        new_func = oldf + [ dcc.Dropdown(options= transformer_options,value = ['passthrough'] ,multi=True,clearable=True, id = 'ColumnTransformer_'+ str(i)) for i in range(len(oldf)-1, int(val))]\n",
    "    elif int(val) < len(oldf) - 1:\n",
    "        new_func =  oldf[:int(val)+1]\n",
    "    else:\n",
    "        new_func =  oldf\n",
    "\n",
    "    try: df = pd.read_json(data,convert_dates = False)\n",
    "    except: df = pd.DataFrame([0], columns = ['0'])\n",
    "    col_cat =  [x for x in df.columns if str(df[x].dtype) == 'int64']\n",
    "    col_num = [x for x in df.columns if str(df[x].dtype) == 'float64']\n",
    "    sorted_vals = [{'label': x, 'value': x} for x in col_num + col_cat] + [ {'label': x, 'value': x} for x in  df.columns if x not in ['Unnamed: 0']+ col_num + col_cat ]\n",
    "    new_c = [oldc[0]]+[ dcc.Dropdown(options= sorted_vals, value = '0' , multi=True,clearable=True, id = 'ColumnSelector_'+ str(i)) for i in range(int(val))]\n",
    "    return new_func, new_c\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(Output(component_id= 'qpcr-data-upload', component_property ='children'),\n",
    "              #Output(component_id= 'qpcrdf', component_property ='options'),\n",
    "              Output('all_qPCR_concat', 'data'),\n",
    "              Input('upload-qPCR2', 'contents'),\n",
    "              State('upload-qPCR2', 'filename'),\n",
    "              State('upload-qPCR2', 'last_modified'))\n",
    "def update_output(list_of_contents, list_of_names, list_of_dates):\n",
    "    if list_of_contents is not None:\n",
    "        children = []\n",
    "        allfasta = []\n",
    "        for contents, filename, date in  zip(list_of_contents, list_of_names, list_of_dates):\n",
    "            content_type, content_string = contents.split(',')\n",
    "            decoded = base64.b64decode(content_string)\n",
    "            try:\n",
    "                if '.fasta' in filename or '.fa' in filename:\n",
    "                    dataset = pd.read_csv(io.StringIO(decoded.decode('utf-8')), sep ='|', lineterminator = '>', header = None) \n",
    "                    dataset[[dataset.columns[-1], 'sequence']] = dataset[dataset.columns[-1]].str.split(expand = True, n = 1)\n",
    "                    dataset.columns = [\"ID\"] + list(dataset.columns[1:] )\n",
    "                    dataset.sequence = dataset.sequence.str.replace('\\n', '').replace('\\r', '')\n",
    "                    dataset.sequence = dataset.sequence.str.upper()\n",
    "                    dataset\n",
    "                    allfasta += [dataset]\n",
    "                elif '.vcf' in filename:\n",
    "                    dataset = pd.read_csv(io.BytesIO(decoded), compression = 'gzip', comment = '#' , delim_whitespace=True, header=None,names = get_vcf_names(io.BytesIO(decoded)))  \n",
    "                    dataset.index = dataset.ID\n",
    "                    dataset = dataset.T.iloc[9:].reset_index()\n",
    "                    dataset['index']\n",
    "                    dataset = pd.concat([dataset['index'].str.split(r'\\||/',expand=True).add_prefix('label_'), dataset.iloc[:,1:]], axis = 'columns')\n",
    "                    allfasta = [dataset]\n",
    "                elif '.csv' in filename:\n",
    "                    dataset = pd.read_csv(io.StringIO(decoded.decode('utf-8'))) \n",
    "\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                children += [html.Div(['There was an error processing '+ filename+ '. Is it at the required file format?' ])]\n",
    "\n",
    "            children += [html.Div([  html.H5(filename), html.Hr() ]) ]\n",
    "\n",
    "\n",
    "        qpcr_files_concat =  pd.concat(allqpcrs).reset_index(drop = True)\n",
    "        vals = [ {'label': x, 'value': x} for x in  qpcr_files_concat.columns]\n",
    "        #merger_id = dcc.Dropdown( options=vals ,  searchable=False, id = 'qpcr_dropdown' , value = 'Sample')\n",
    "        return children,  qpcr_files_concat.to_json()\n",
    "    return html.Div(), pd.DataFrame(np.zeros([1,1])).to_json()\n",
    "\n",
    "\n",
    "@app.callback(Output(component_id= 'habitat-data-upload', component_property ='children'),\n",
    "              Output(component_id= 'habitatdf', component_property ='options'),\n",
    "              Output('habitatcsv', 'data'),\n",
    "              Input('upload-habitat', 'contents'),\n",
    "              State('upload-habitat', 'filename'),\n",
    "              State('upload-habitat', 'last_modified'))\n",
    "def update_output_hab(list_of_contents, list_of_names, list_of_dates):\n",
    "    if list_of_contents is not None:\n",
    "        children = []\n",
    "        for contents, filename, date in  zip(list_of_contents, list_of_names, list_of_dates):\n",
    "            content_type, content_string = contents.split(',')\n",
    "            decoded = base64.b64decode(content_string)\n",
    "            try:\n",
    "                if 'csv' in filename:   allhabs = pd.read_csv(io.StringIO(decoded.decode('utf-8')))\n",
    "                if 'tsv' in filename:   allhabs = pd.read_csv(io.StringIO(decoded.decode('utf-8')), sep= '\\t')\n",
    "                elif 'xls' in filename: allhabs = pd.read_excel(io.BytesIO(decoded))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                children += [html.Div(['There was an error processing this file.' ])]\n",
    "\n",
    "            children += [html.Div([  html.H5(filename), html.Hr()])   ]\n",
    "\n",
    "        vals = [ {'label': x, 'value': x} for x in  allhabs.columns]\n",
    "        #merger_id = dcc.Dropdown( options=vals )#, id = 'hab_dropdown') ,  searchable=False\n",
    "        return children, vals, allhabs.to_json()\n",
    "    return html.Div(),[], pd.DataFrame(np.zeros([1,1])).to_json()\n",
    "\n",
    "@app.callback(Output(component_id= 'UMAP_cat', component_property ='options'),  Output(component_id= 'UMAP_cat', component_property ='value'),\n",
    "              Output(component_id= 'UMAP_y', component_property ='options'),  Output(component_id= 'UMAP_y', component_property ='value'),\n",
    "              Output(component_id= 'UMAP_cont', component_property ='options'), Output(component_id= 'UMAP_cont', component_property ='value'),\n",
    "              Output(component_id= 'ML_target', component_property ='options'),  Output(component_id= 'ML_target', component_property ='value'),\n",
    "              Output(component_id= 'prophet_y', component_property ='options'),  Output(component_id= 'prophet_y', component_property ='value'),\n",
    "              Output(component_id= 'prophet_ds', component_property ='options'),  Output(component_id= 'prophet_ds', component_property ='value'),\n",
    "              Output(component_id= 'prophet_regressors', component_property ='options'),  Output(component_id= 'prophet_regressors', component_property ='value'),\n",
    "              Input(component_id= 'Merged_df', component_property ='children'), Input(component_id= 'df', component_property ='data'))\n",
    "              #State(component_id= 'preprocessing_columns', component_property ='children'))\n",
    "def update_UMAP_and_ML_select_columns(inpt, data): #, columns_list_id\n",
    "    #if data != {'namespace': 'dash_html_components', 'props': {'children': None}, 'type': 'Div'} and data != None and inpt['type'] != 'Div':\n",
    "    try:\n",
    "        df = pd.read_json(data)\n",
    "        vals = [ {'label': x, 'value': x} for x in  df.columns if x not in ['Unnamed: 0']]\n",
    "        col_cat =  [x for x in df.columns if str(df[x].dtype) == 'int64']\n",
    "        col_num = [x for x in df.columns if str(df[x].dtype) == 'float64']\n",
    "        col_object = [x for x in df.columns if (str(df[x].dtype) in ['object', 'datetime64[ns]'] )]\n",
    "        sorted_vals = [{'label': x, 'value': x} for x in col_num + col_cat] + [ {'label': x, 'value': x} for x in  df.columns if x not in ['Unnamed: 0']+ col_num + col_cat ]\n",
    "        if len(col_object) > 0:\n",
    "            if 'date' in col_object: col_object = 'date'\n",
    "            elif 'datetime' in col_object: col_object = 'datetime'\n",
    "            else: col_object = col_object[0]\n",
    "        vals_object = [ {'label': x, 'value': x} for x in  df.columns  if (str(df[x].dtype) in ['object', 'datetime64[ns]'] )]\n",
    "        vals_plus_umap = sorted_vals +  [{'label': 'UMAP_'+str(x), 'value': 'UMAP_'+str(x)} for x in range(1,3)]\n",
    "        #prep_cols =  [columns_list_id[0]]+[ dcc.Dropdown(options= [{'label': x, 'value': x} for x in df.columns], value = df.columns[0] , multi=True,clearable=True, id = 'ColumnSelector_'+ str(i)) for i in range(len(columns_list_id)+1)]\n",
    "\n",
    "        return sorted_vals, col_object,  sorted_vals, [], sorted_vals,col_num +col_cat,  sorted_vals, ['eDNA frq'], vals_plus_umap, [], vals_object,col_object,  vals_plus_umap, []\n",
    "\n",
    "    except:\n",
    "        return [], [], [], [], [],[], [], [], [], [],[], [],[], []  #, columns_list_id  str(fixed_dataset.date.dtype) == 'object'\n",
    "\n",
    "\n",
    "@app.callback(Output(component_id= 'UMAP_view', component_property ='figure'),\n",
    "              Output(component_id= 'df_with_umap', component_property ='data'),\n",
    "              Output(component_id= 'graph', component_property ='children'),\n",
    "              Output(component_id= 'cytoscape', component_property ='children'),\n",
    "              Input('UMAP_start', 'n_clicks'),\n",
    "              State('UMAP_cat', 'value'),\n",
    "              State('UMAP_cont', 'value'),\n",
    "              State('UMAP_y', 'value'),\n",
    "              State('n_neighboors', 'value'),\n",
    "              State('UMAP_radio', 'value'),\n",
    "              State(component_id= 'preprocessing_columns', component_property ='children'),\n",
    "              State(component_id= 'preprocessing_functions', component_property ='children'),\n",
    "              State(component_id = 'clf_disp', component_property = 'value'),\n",
    "              State(component_id= 'df', component_property ='data'))\n",
    "def generate_UMAP(clicked, cat_labels, cont_labels,y ,n_nb, radio_val,MLcolumns, MLfuncs, MLclassif, dataframe_json):\n",
    "    umap_list = []\n",
    "    if dataframe_json != None:\n",
    "        df = pd.read_json(dataframe_json).dropna()\n",
    "        #### sample if dataframe is too big\n",
    "        if df.shape[0] > 2000:\n",
    "            df = df.sample(2000)\n",
    "        if y == None or y == []:\n",
    "            if len(cont_labels) > 0:\n",
    "                if radio_val == 2: preprocessed_data = StandardScaler().fit_transform(df[cont_labels])\n",
    "                if radio_val == 1: preprocessed_data = df[cont_labels]\n",
    "                if radio_val == 3: preprocessed_data = inpt_children_to_pipe(MLcolumns, MLfuncs, MLclassif)['preprocessing'].fit_transform(df)\n",
    "                umap_list += [umap.UMAP(n_neighbors = n_nb).fit(preprocessed_data)]\n",
    "            if len(cat_labels) > 0:\n",
    "                try: umap_list += [umap.UMAP(metric=\"jaccard\", n_neighbors=150).fit(make_pipeline(OneHotEncoder()).fit_transform(df[cat_labels]))]\n",
    "                except: umap_list += [umap.UMAP(metric=\"jaccard\", n_neighbors=150).fit(make_pipeline(OrdinalEncoder(), MinMaxScaler()).fit_transform(df[cat_labels]))]\n",
    "        else:# len(y) > 0:#:\n",
    "            if len(cont_labels) > 0:\n",
    "                if radio_val == 2: preprocessed_data = StandardScaler().fit_transform(df[cont_labels])\n",
    "                if radio_val == 1: preprocessed_data = df[cont_labels]\n",
    "                if radio_val == 3: preprocessed_data = inpt_children_to_pipe(MLcolumns, MLfuncs, MLclassif)['preprocessing'].fit_transform(df)\n",
    "                umap_list +=[umap.UMAP(n_neighbors = n_nb).fit(preprocessed_data,y=df[y])]\n",
    "            if len(cat_labels) > 0:\n",
    "                try: umap_list += [umap.UMAP(metric=\"jaccard\", n_neighbors=150).fit(make_pipeline(OneHotEncoder()).fit_transform(df[cat_labels]),y=df[y])]\n",
    "                except: umap_list += [umap.UMAP(metric=\"jaccard\", n_neighbors=150).fit(make_pipeline(OrdinalEncoder(), MinMaxScaler()).fit_transform(df[cat_labels]),y=df[y])]\n",
    "\n",
    "        if len(umap_list) > 1: UMAP = umap_list[0] + umap_list[1]\n",
    "        elif len(umap_list) == 1: UMAP = umap_list[0]\n",
    "        else: return html.Div(), pd.DataFrame(np.zeros([1,1])).to_json() , html.Div()\n",
    "        umap_df = pd.DataFrame(UMAP.embedding_, index = df.index, columns = ['UMAP_1', 'UMAP_2'])\n",
    "        df = pd.concat([df, umap_df], axis = 1)\n",
    "        cluster = hdbscan.HDBSCAN(min_cluster_size=10, gen_min_span_tree=True)\n",
    "        df['hdbscan'] =  cluster.fit_predict(df[['UMAP_1', 'UMAP_2']])\n",
    "        df.columns = [x.replace(' ', '_') for x in df.columns]\n",
    "        dfscatter = df.copy()\n",
    "        dfscatter['hdbscan'] = dfscatter['hdbscan'].apply(str) #------- covert to str ------------\n",
    "        dfscatter = dfscatter.reset_index()\n",
    "\n",
    "        #------------------------------------------------- generate graph of distances! ----------------------\n",
    "        default_stylesheet_cyto = [\n",
    "        {'selector': '[degree < 15]',\n",
    "        'style': {\n",
    "            'background-color': '#223c4f',# '#223c4f',\n",
    "            'label': 'data(id)',\n",
    "            'width': \"30%\",\n",
    "            'height': \"30%\"\n",
    "        }},\n",
    "        {'selector': 'edge',\n",
    "        'style': {\n",
    "            'line-color': '#223c4f',#\"mapData(weight, 0, 10, blue, red)\",\n",
    "            \"mid-target-arrow-color\": \"red\",\n",
    "            \"mid-target-arrow-shape\": \"vee\"\n",
    "            # '#223c4f', line-color\n",
    "        }},\n",
    "        {'selector': '[degree >= 15]',\n",
    "        'style': {\n",
    "            'background-color': 'red',# '#223c4f', line-color\n",
    "            #'shape': 'rectangle',\n",
    "            'label': 'data(id)',\n",
    "            'width': \"40%\",\n",
    "            'height': \"40%\"\n",
    "        }}\n",
    "\n",
    "         ]\n",
    "        if df.shape[0] < 200:\n",
    "        #cyt = nx.cytoscape_data(cluster.minimum_spanning_tree_.to_networkx())['elements']\n",
    "            cyt = nx.from_scipy_sparse_matrix(kneighbors_graph(umap_df, 2, mode = 'distance', include_self= False, n_jobs = -1), create_using=nx.DiGraph)\n",
    "            #cytodisplay1 = cyto.Cytoscape(id='cytoscape', layout={'name': 'cose'},style={'width': '80%', 'height': '300px'}, elements = plotly_cyt2(cyt)) #\n",
    "\n",
    "            cytodisplay2 = cyto.Cytoscape(id='cytoscape', layout={'name': 'cose'},style={'width': '1000px', 'height': '1000px'},\n",
    "                                          stylesheet = default_stylesheet_cyto,\n",
    "                                          elements = plotly_cyt3(cyt)) #{'width': '2000px', 'height': '1000px'}\n",
    "        else:\n",
    "            #df_colors_sns = pd.DataFrame(MinMaxScaler(feature_range = (-2,2)).fit_transform(dfscatter[['UMAP_1','UMAP_2']]), columns = ['UMAP_1','UMAP_2'])#.dropna(axis = 1)\n",
    "            #colors_sns = pd.concat([make_colormap_clustering('hdbscan', 'tab10',0, dfscatter.dropna(axis = 1)),\n",
    "            #                       make_colormap_clustering('UMAP_1', 'PiYG',1, df_colors_sns).apply(lambda x: x[:-1]),\n",
    "            #                        make_colormap_clustering('UMAP_2', 'PiYG',1, df_colors_sns)], axis = 1)\n",
    "            ##### added a dropna in clustermap NAs are creeping in from somewhere\n",
    "            #row_dism = 1 - df.drop(['UMAP_1','UMAP_2', 'hdbscan'], axis=1).T.corr()\n",
    "            #row_linkage = hc.linkage(sp.distance.squareform(row_dism), method='complete')\n",
    "            #sns.clustermap(dfscatter[[x.replace(' ', '_') for x in cont_labels]].astype(int), figsize=(15,15),cmap = sns.diverging_palette(20, 220, as_cmap=True), z_score = 1, cbar_pos = None, vmax = 2, vmin = -2,\n",
    "            #               row_colors =colors_sns , dendrogram_ratio=(.2, .1), col_cluster=False, row_cluster = False) #col_cluster=False  row_linkage=row_linkage .drop(['UMAP_1','UMAP_2', 'hdbscan'], axis=1)\n",
    "            #fig1 = plt.gcf()\n",
    "            #fig1.tight_layout()\n",
    "            #cytodisplay2 = mplfig2html(fig1) #mplfig2html(fig1) --------------- edited here---------------------------\n",
    "            cytodisplay2 = dcc.Graph(figure=dashbio.Clustergram(\n",
    "                data=dfscatter[[x.replace(' ', '_') for x in cont_labels]].astype(int).values,\n",
    "                row_labels=list(dfscatter.index),\n",
    "                column_labels=[x.replace(' ', '_') for x in cont_labels],\n",
    "                cluster = 'row', hidden_labels='row',width=1500,height=1200) )\n",
    "\n",
    "        #### image from hdbscan\n",
    "        pic_IObytes = io.BytesIO()\n",
    "        fig = plt.figure(figsize = [16,6], dpi = 100)\n",
    "        ax = fig.add_subplot(121)\n",
    "        ax = cluster.single_linkage_tree_.plot(cmap='viridis', colorbar=False)\n",
    "        ax2 = fig.add_subplot(122)\n",
    "        ax2 = cluster.minimum_spanning_tree_.plot(edge_cmap='viridis',edge_alpha=0.6, node_size=80,   edge_linewidth=2)\n",
    "        sns.despine()\n",
    "        fig.savefig(pic_IObytes,  format='png')\n",
    "        fig.clear()\n",
    "        #lpotlyfigured2 = mpl2plotlyGraph(fig)\n",
    "        pic_IObytes.seek(0)\n",
    "\n",
    "        graph_part = [ html.Img(src ='data:image/png;base64,{}'.format(base64.b64encode(pic_IObytes.read()).decode()))]#cytodisplay ,cytodisplay1\n",
    "        #graph_part = [lpotlyfigured2]\n",
    "\n",
    "        return px.scatter(dfscatter, x=\"UMAP_1\", y=\"UMAP_2\", color = 'hdbscan', hover_data=dfscatter.columns, template='plotly',height=1200, width=1500), df.to_json(), graph_part,cytodisplay2\n",
    "        #return dcc.Graph(figure= px.scatter(dfscatter, x=\"UMAP_1\", y=\"UMAP_2\", color = 'hdbscan', hover_data=dfscatter.columns, template='plotly',height=1200, width=1500), id = 'umap_plot_selectable'), df.to_json(), graph_part,cytodisplay2\n",
    "    return px.scatter(x = [0], y = [0]), pd.DataFrame(np.zeros([1,1])).to_json(), html.Div(), html.Div()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(Output(component_id= 'selected_points_umap', component_property ='data'),\n",
    "              Output(component_id= 'umap_selected_stats', component_property ='children'),\n",
    "              Input(component_id= 'UMAP_view', component_property ='selectedData'),\n",
    "              State(component_id= 'df_with_umap', component_property ='data'))\n",
    "def store_selected_umap_points(x, json_df):\n",
    "    if x and x['points']:\n",
    "        try:\n",
    "            region = pd.concat([pd.DataFrame(i) for i in x['points']])\n",
    "            indices = region.groupby(['curveNumber','pointIndex']).first().customdata.unique()\n",
    "            dataset = pd.read_json(json_df,convert_dates = False)\n",
    "            subset = dataset.iloc[indices] #.apply(lambda w: w[0])\n",
    "            outer_group = dataset.copy().drop(indices, axis = 0)\n",
    "            subset_describe = subset.describe().fillna(-999).T.reset_index() #include='all'\n",
    "            subset_describe['ttest_p-value'] = subset_describe['index'].apply(lambda x: ttest_ind(subset[x], outer_group[x], equal_var = False)[1])\n",
    "            subset_describe['ttest1samp_p-value'] = subset_describe['index'].apply(lambda x: ttest_1samp(subset[x], dataset[x].mean()).pvalue)\n",
    "\n",
    "            subset_describe = subset_describe[['index', 'count', 'mean', 'std', 'ttest_p-value','ttest1samp_p-value', 'min', 'max', '50%', '25%', '75%']]\n",
    "        except:\n",
    "            return pd.DataFrame(np.zeros([1,1])).to_json(), html.Div(str(list(region['customdata'].apply(lambda w: int(w)).unique())))\n",
    "        return subset.to_json(), dash_table.DataTable( data=subset_describe.to_dict('records'), columns=[{'name': str(i), 'id': str(i),\n",
    "                                                                                                         'type':'numeric', 'format': Format(precision=5, scheme=Scheme.fixed)\n",
    "                                                                                                         } for i in subset_describe.columns], style_table={'overflowX': 'auto'},\n",
    "                                                      style_cell={'minWidth': '180px', 'width': '90px', 'maxWidth': '180px','overflow': 'hidden','textOverflow': 'ellipsis'}, style_as_list_view=True,\n",
    "                                                     style_data_conditional=[ {'if': {'row_index': 'odd'}, 'backgroundColor': 'rgb(248, 248, 248)'} ,\n",
    "                                                                              {'if': {'column_id': 'ttest_p-value',  'filter_query': '{ttest_p-value} <= 0.05'}, 'color': 'red','fontWeight': 'bold'},\n",
    "                                                                              {'if': {'column_id': 'ttest1samp_p-value',  'filter_query': '{ttest1samp_p-value} <= 0.05'}, 'color': 'red','fontWeight': 'bold'}],\n",
    "                                                      style_header={'backgroundColor': 'rgb(230, 230, 230)','fontWeight': 'bold'} )\n",
    "    else:\n",
    "        return pd.DataFrame(np.zeros([1,1])).to_json(), html.Div()\n",
    "\n",
    "\n",
    "@app.callback(Output(component_id= 'prophet_future_dates', component_property ='start_date'),\n",
    "              Output(component_id= 'prophet_future_dates', component_property ='end_date'),\n",
    "              Output(component_id= 'prophet_remove_months', component_property ='value'),\n",
    "              Output(component_id= 'prophet_remove_days_of_the_week', component_property ='value'),\n",
    "              Output(component_id= 'prophet_remove_hours', component_property ='value'),\n",
    "              Input(component_id= 'prophet_ds', component_property ='value'),\n",
    "              Input(component_id= 'prophet_regressors', component_property ='value'),\n",
    "              State(component_id= 'df', component_property ='data'),\n",
    "              )\n",
    "def add_prophet_future(ds_column,regressors, data ):\n",
    "    try: df = pd.read_json(data)\n",
    "    except: return datetime.datetime.now().strftime('%b %d %Y'), (datetime.datetime.now() +  + datetime.timedelta(365)).strftime('%b %d %Y'), [],[],[]\n",
    "    df[ds_column] = df[ds_column].apply(lambda x: pd.to_datetime(x, format='%y-%m-%d',errors='coerce'))\n",
    "    if len(regressors)> 0:\n",
    "        ranged = df[df[ds_column].dt.year == df[ds_column].dt.year.max()].copy()\n",
    "        start = (ranged[ds_column].min() + datetime.timedelta(365)).strftime('%b %d %Y')\n",
    "        end = (ranged[ds_column].max() + datetime.timedelta(365)).strftime('%b %d %Y')\n",
    "    else:\n",
    "        start = (df[ds_column].max() + datetime.timedelta(1)).strftime('%b %d %Y')\n",
    "        end = (df[ds_column].max() + datetime.timedelta(366)).strftime('%b %d %Y')\n",
    "    not_present_months = [x for x in range(1,13) if x not in df[ds_column].dt.month.unique()]\n",
    "    not_present_weekdays = [x for x in range(7) if x not in df[ds_column].dt.weekday.unique()]\n",
    "    not_present_hours = [x for x in range(24) if x not in df[ds_column].dt.hour.unique()]\n",
    "\n",
    "    return start, end, not_present_months, not_present_weekdays, not_present_hours\n",
    "\n",
    "@app.callback(Output(component_id= 'prophet_plots', component_property ='children'),\n",
    "              Input(component_id= 'run_prophet', component_property ='n_clicks'),\n",
    "              State(component_id= 'df', component_property ='data'),\n",
    "              State(component_id= 'df_with_umap', component_property ='data'), #  ,\n",
    "              State(component_id= 'prophet_y', component_property ='value'),\n",
    "              State(component_id= 'prophet_ds', component_property ='value'),\n",
    "              State(component_id= 'prophet_regressors', component_property ='value'),\n",
    "              State(component_id= 'prophet_rolling_average', component_property ='value'),\n",
    "              State(component_id= 'prophet_growth', component_property ='value'),\n",
    "              State(component_id= 'prophet_cap', component_property ='value'),\n",
    "              State(component_id= 'prophet_floor', component_property ='value'),\n",
    "              State(component_id= 'prophet_seasonality', component_property ='value'),\n",
    "              State(component_id= 'seasonality_mode', component_property ='value'),\n",
    "              State(component_id= 'season_prior', component_property ='value'),\n",
    "              State(component_id= 'prophet_n_change_points', component_property ='value'),\n",
    "              State(component_id= 'changepoint_prior', component_property ='value'),\n",
    "              State(component_id= 'changepoint_range', component_property ='value'),\n",
    "              State(component_id= 'prophet_future_dates', component_property ='start_date'),\n",
    "              State(component_id= 'prophet_future_dates', component_property ='end_date'),\n",
    "              State(component_id= 'prophet_remove_months', component_property ='value'),\n",
    "              State(component_id= 'prophet_remove_days_of_the_week', component_property ='value'),\n",
    "              State(component_id= 'prophet_remove_hours', component_property ='value'))\n",
    "def run_fbprophet(click,data, data_umap, y_column, ds_column, regressors, rolling_avg, growth, cap, floor, seasonality, season_mode, season_scale, change_points_n, change_points_prior, change_points_range,\n",
    "                 forecast_range_start,forecast_range_end, removed_months, removed_weekdays, removed_hours):\n",
    "    if data != None:\n",
    "        df = pd.read_json(data)# parse_dates=[ds_column]\n",
    "        df2 = pd.read_json(data_umap) #parse_dates=[ds_column]\n",
    "        if df2.shape[1] > df.shape[1]:\n",
    "            df = df2\n",
    "            ds_column = ds_column.replace(' ', '_')\n",
    "            y_column = y_column.replace(' ', '_')\n",
    "            regressors = [x.replace(' ', '_') for x in regressors]\n",
    "        #if use_ml_pipe == True: preprocessed_data = inpt_children_to_pipe(MLcolumns, MLfuncs, MLclassif)['preprocessing'].fit_transform(df)\n",
    "        df[ds_column] = df[ds_column].apply(lambda x: pd.to_datetime(x, format='%y-%m-%d',errors='coerce'))\n",
    "        df= df[pd.notnull(df[ds_column])]\n",
    "        df = df.sort_values(ds_column)\n",
    "        if rolling_avg > 0.1:\n",
    "            df = df.set_index(ds_column)\n",
    "            df = df.rolling(window= str(int(rolling_avg *24))+'H').mean().reset_index()\n",
    "            #resampled_data = fixed_dataset_time.resample('20d').mean().dropna().reset_index()\n",
    "\n",
    "        df = df[[ds_column, y_column]+ regressors]\n",
    "        df.columns = ['ds', 'y']+ regressors\n",
    "        if df.shape[0] > 2000:\n",
    "            df = df.sample(2000)\n",
    "\n",
    "        season_true_kwards = {x: 25 for x in seasonality}\n",
    "        season_false_kwards = {x: False for x in ['yearly_seasonality', 'weekly_seasonality', 'daily_seasonality'] if x not in seasonality}\n",
    "\n",
    "        if growth == 'logistic':\n",
    "            df['cap'] = cap\n",
    "            df['floor'] = floor\n",
    "\n",
    "        df = df[~(df['ds'].dt.month.isin(removed_months))]\n",
    "        df = df[~(df['ds'].dt.weekday.isin(removed_months))]\n",
    "        df = df.query('ds.dt.hour not in @removed_hours')\n",
    "\n",
    "\n",
    "        fbmodel = Prophet(growth = growth,seasonality_mode =season_mode, seasonality_prior_scale =season_scale,\n",
    "                          n_changepoints= change_points_n, changepoint_prior_scale=change_points_prior , changepoint_range = change_points_range,\n",
    "                          **season_true_kwards, **season_false_kwards) #mcmc_samples=100\n",
    "\n",
    "        for i in regressors:\n",
    "            fbmodel.add_regressor(i)\n",
    "\n",
    "        fbmodel.fit(df)\n",
    "\n",
    "        if len(regressors) > 0:\n",
    "            future = df[df.ds.dt.year == df.ds.dt.year.max()].copy()\n",
    "            future.ds += pd.to_timedelta(365, unit='d')\n",
    "\n",
    "        elif 'daily_seasonality' not in seasonality:\n",
    "            future = pd.DataFrame(pd.date_range(pd.to_datetime(forecast_range_start), pd.to_datetime(forecast_range_end),freq='d'), columns = ['ds'])\n",
    "        else:\n",
    "            future = pd.DataFrame(pd.date_range(pd.to_datetime(forecast_range_start), pd.to_datetime(forecast_range_end),freq='H'), columns = ['ds'])\n",
    "\n",
    "        future = future[~(future['ds'].dt.month.isin(removed_months))]\n",
    "        future = future[~(future['ds'].dt.weekday.isin(removed_months))]\n",
    "        future = future.query('ds.dt.hour not in @removed_hours')\n",
    "\n",
    "        if growth == 'logistic':\n",
    "            future['cap'] = cap\n",
    "            future['floor'] = floor\n",
    "\n",
    "        forecast = fbmodel.predict(pd.concat([df, future], axis = 0).reset_index())\n",
    "\n",
    "        returnable = [dcc.Graph(figure= plot_plotly(fbmodel,forecast, figsize = (1550, 1200),  xlabel=ds_column, ylabel=y_column), id = 'prophet_forecast_plot', ),\n",
    "                      dcc.Graph(figure= plot_components_plotly(fbmodel,forecast, figsize = (1550, 450)), id = 'prophet_forecast_components')]\n",
    "        if len(regressors) > 0:\n",
    "            regressor_coefs = regressor_coefficients(fbmodel)\n",
    "            regressor_coefs\n",
    "            regressor_coefs['coef_abs'] = regressor_coefs.coef.apply(abs)\n",
    "            regressor_coefs = regressor_coefs.sort_values('coef_abs', ascending = False)\n",
    "            #sns.barplot(x = 'regressor', y = 'coef', data =regressor_coefs)\n",
    "            fig00 = px.bar(regressor_coefs, x=\"regressor\", y=\"coef\", hover_data=regressor_coefs.columns, template='plotly',height=1000, width=1550)\n",
    "            returnable += [dcc.Graph(figure = fig00, id='regressor_impt')] #[mplfig2html(fig1)]\n",
    "\n",
    "        returnable_tabs = dcc.Tabs([dcc.Tab(children = content, label = name) for name,content in zip(['timeline', 'components', 'regressor coeficients'], returnable)])\n",
    "\n",
    "        return returnable_tabs\n",
    "\n",
    "    return html.Div()\n",
    "\n",
    "\n",
    "@app.callback(Output(component_id= 'Merged_df', component_property ='children'),\n",
    "              Output(component_id= 'df', component_property ='data'),\n",
    "              Output(component_id= 'direct_dataframe_upload_name', component_property = 'children'),\n",
    "              Input('habitatdf', 'value'),\n",
    "              Input('upload_dataset_directly', 'contents'),\n",
    "              State('upload_dataset_directly', 'filename'),\n",
    "              State('upload_dataset_directly', 'last_modified'),\n",
    "              State('all_qPCR_concat', 'data'),\n",
    "              State('habitatcsv', 'data'))\n",
    "def merge_csv_update_spreadsheet(hab, up_content, up_filename,  up_date , df_qpcr_json, df_hab_json): #qpcr,\n",
    "    ctx = dash.callback_context.triggered[0]['prop_id'].split('.')[0]\n",
    "    if  hab != None and ctx == 'habitatdf': # and qpcr != None:\n",
    "        try : left_merge, right_merge =  hab, 'Sample' #qpcr\n",
    "        except:\n",
    "            return   html.Div(), html.Hr(className=\"my-2\"), html.Div(),\n",
    "\n",
    "        try: df, df_hab = pd.read_json(df_qpcr_json), pd.read_json(df_hab_json)\n",
    "        except Exception as e:\n",
    "            return   html.H4('no data'), html.Hr(className=\"my-2\"), html.Div(),\n",
    "\n",
    "        final = df_hab.merge(frequencies,left_on = left_merge, right_on = df.columns[0], how = 'inner' )\n",
    "        return  dbc.Jumbotron([ html.H1(\"Overview of your dataset\", className=\"display-3\"),\n",
    "                               html.Iframe(srcDoc = ProfileReport(final,  correlations=None,interactions=None, minimal=True).to_html(), height='18000', width='2350')]),  final.to_json(), html.Div() #interactions=None,\n",
    "    elif up_content != None and ctx == 'upload_dataset_directly':\n",
    "        content_type, content_string = up_content.split(',')\n",
    "        decoded = base64.b64decode(content_string)\n",
    "        if '.csv' in up_filename:\n",
    "            final = pd.read_csv(io.StringIO(decoded.decode('utf-8')))\n",
    "        elif '.tsv' in up_filename:\n",
    "            final = pd.read_csv(io.StringIO(decoded.decode('utf-8')), sep='\\t')\n",
    "        elif '.vcf' in up_filename:\n",
    "            final = pd.read_csv(io.BytesIO(decoded), compression = 'gzip', comment = '#' , delim_whitespace=True, header=None,names = get_vcf_names(io.BytesIO(decoded)))  \n",
    "            final.index = final.ID\n",
    "            final = final.T.iloc[9:].reset_index()\n",
    "            final['index']\n",
    "            final = pd.concat([final['index'].str.split(r'\\||/',expand=True).add_prefix('label_'), final.iloc[:,1:]], axis = 'columns')\n",
    "            \n",
    "        else: return html.Div('file type not accepted, is it a csv or a tsv?'),html.Div(), html.Div([  html.H5(up_filename), html.Hr() ])\n",
    "        return  [ html.Div('skipping pandas profiler')],final.to_json(), html.Div([html.H5(up_filename), html.Hr()]) #23\n",
    "        return  [ html.Iframe(srcDoc = ProfileReport(final, correlations=None, interactions=None).to_html(), height='18000', width='2000')],final.to_json(), html.Div([html.H5(up_filename), html.Hr()]) #2350 interactions=None,\n",
    "\n",
    "    else: return html.Div(),html.Div(), html.Div()\n",
    "\n",
    "@app.callback(Output(component_id= 'keplermap', component_property ='children'),\n",
    "              Input(component_id= 'df', component_property ='data'),\n",
    "              Input(component_id= 'df_with_umap', component_property ='data'),\n",
    "              Input(component_id= 'selected_points_umap', component_property ='data'))\n",
    "def Generate_map(data, datau, umap_selelection):\n",
    "    ret_map = KeplerGl()\n",
    "    try: ret_map.add_data(data=pd.read_json(umap_selelection,convert_dates = False), name='Selected area UMAP')\n",
    "    except: pass\n",
    "    try: ret_map.add_data(data=pd.read_json(datau,convert_dates = False), name='Dataset w/ UMAP')\n",
    "    except: pass\n",
    "    try: ret_map.add_data(data=pd.read_json(data,convert_dates = False), name='Dataset')\n",
    "    except: pass\n",
    "\n",
    "    ###--------------------------------------get better map---------------------------------------------------------\n",
    "    ret_map.config = {\"mapStyle\": {\n",
    "      \"topLayerGroups\": {},\n",
    "      \"visibleLayerGroups\": {  \"label\": True, \"road\": True,\"building\": True, \"water\": True, \"land\": True},\n",
    "      \"threeDBuildingColor\": [194.6103322548211,  191.81688250953655,  185.2988331038727  ]}}\n",
    "\n",
    "    \n",
    "    return html.Iframe(srcDoc = ret_map._repr_html_().decode(), height='1343', width='2380')#  height='1343', width='2380'\n",
    "\n",
    "#\n",
    "app.run_server(mode='external', debug=True, host = '127.0.0.1', port = 8097,dev_tools_ui=True, threaded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20eb4638-7ad6-4dd6-bc0b-a9a4b1d5f461",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_viewer = [\n",
    "    dbc.Jumbotron([\n",
    "    dashbio.Pileup(\n",
    "        id = 'genome_viewer_pileup',\n",
    "        range = {'contig':'NC_045512v2' ,'start':0, 'stop':30000},  #         \n",
    "        reference = {\n",
    "            'label': 'wuhCor1',\n",
    "            'url': 'http://hgdownload.soe.ucsc.edu/goldenPath/wuhCor1/bigZips/wuhCor1.2bit'\n",
    "        },\n",
    "        tracks = [\n",
    "            {'viz': 'scale', 'label': 'Scale' },\n",
    "            {'viz': 'location', 'label': 'Location'},\n",
    "            {'viz': 'features', 'label': 'ncbi genes', 'source': 'bigBed', 'sourceOptions': {'url': 'https://hgdownload.soe.ucsc.edu/gbdb/wuhCor1/bbi/ncbi/genes.bb'}    },\n",
    "            #{'viz': 'features', 'label': 'testing here', 'source': 'bigBed', 'sourceOptions': {'url': 'https://hgdownload.soe.ucsc.edu/gbdb/wuhCor1/bbi/pdb.bb'}    },\n",
    "            {'viz': 'features', 'label': 'vaccine', 'source': 'bigBed', 'sourceOptions': {'url': 'https://hgdownload.soe.ucsc.edu/gbdb/wuhCor1/bbi/wuhCor1.vaccines.bb'} ,'vizOptions': { 'color': {'rgb': {'r': 255, 'g': 0, 'b': 0, 'a': 1}},'collapse': False}   },\n",
    "            #{'viz': 'features', 'label': 'ncbi peptides', 'source': 'bigBed', 'sourceOptions': {'url': 'https://hgdownload.soe.ucsc.edu/gbdb/wuhCor1/bbi/ncbi/peptides.bb'}    }, \n",
    "            {'viz': 'features', 'label': 'spike mutations', 'source': 'bigBed', 'sourceOptions': {'url': 'https://hgdownload.soe.ucsc.edu/gbdb/wuhCor1/spikeMuts/spikeMuts.bb','vizOptions': { 'color': {'rgb': {'r': 255, 'g': 0, 'b': 0, 'a': 1}},'collapse': False}},},\n",
    "            {'viz': 'features', 'label': 'Variant B.1.1.7', 'source': 'bigBed', 'sourceOptions': {'url': 'https://hgdownload.soe.ucsc.edu/gbdb/wuhCor1/strainMuts/variantAaMuts_B.1.1.7_2021_02_05.bb','vizOptions': { 'color': {'rgb': {'r': 255, 'g': 0, 'b': 0, 'a': 1}},'collapse': False}},},\n",
    "            {'viz': 'features', 'label': 'Variant B.1.351', 'source': 'bigBed', 'sourceOptions': {'url': 'https://hgdownload.soe.ucsc.edu/gbdb/wuhCor1/strainMuts/variantAaMuts_B.1.351_2021_02_05.bb','vizOptions': { 'color': {'rgb': {'r': 255, 'g': 0, 'b': 0, 'a': 1}},'collapse': False}},},\n",
    "            {'viz': 'features', 'label': 'Variant B.1.429', 'source': 'bigBed', 'sourceOptions': {'url': 'https://hgdownload.soe.ucsc.edu/gbdb/wuhCor1/strainMuts/variantAaMuts_B.1.429_2021_02_05.bb','vizOptions': { 'color': {'rgb': {'r': 255, 'g': 0, 'b': 0, 'a': 1}},'collapse': False}},},\n",
    "            {'viz': 'features', 'label': 'Variant P1', 'source': 'bigBed', 'sourceOptions': {'url': 'https://hgdownload.soe.ucsc.edu/gbdb/wuhCor1/strainMuts/variantAaMuts_P.1_2021_02_05.bb','vizOptions': { 'color': {'rgb': {'r': 255, 'g': 0, 'b': 0, 'a': 1}},'collapse': False}},},\n",
    "            #{'viz': 'features', 'label': 'NextStrain Clade', 'source': 'bigBed', 'sourceOptions': {'url': 'https://hgdownload.soe.ucsc.edu/gbdb/wuhCor1/nextstrain/nextstrainClade.bb','vizOptions': { 'color': {'rgb': {'r': 255, 'g': 0, 'b': 0, 'a': 1}},'collapse': False}},},\n",
    "            {'viz': 'features', 'label': 'artic primers', 'source': 'bigBed', 'sourceOptions': {'url': 'https://hgdownload.soe.ucsc.edu/gbdb/wuhCor1/bbi/artic.bb'}},\n",
    "            #{'viz': 'variants', 'label': 'data', 'source': 'variantJson', 'sourceOptions': dataset.to_json(orient=\"table\")}\n",
    "        ]\n",
    "    ),\n",
    " ])\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf156f9f-8f8b-48b0-b9d0-0bf31750854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40012b61-8baa-4343-bc97-d3ed9331d3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb14ecc8-de75-4a97-b173-f2b9ffd47757",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time \n",
    "#dataset = pd.read_csv('public.all.minAf.001.txt', comment = '#' , delim_whitespace=True, header=None,names = get_vcf_names('public.all.minAf.001.vcf.gz')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d7bd96-fc89-49e3-a637-0048a82b875a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec8eadfd-5a97-40a6-b9c3-ec5fdfba89df",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_anotations = pd.read_csv('gene_annotation_SarsCoV2.gff.gz', compression = 'gzip', comment = '#' , sep ='\\t', header = None,names = ['seqid', 'source', 'type', 'start', 'end', 'score', 'strand', 'phase', 'attributes']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51f8ccb7-4d30-4932-9296-a355cce5ce2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqid</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>score</th>\n",
       "      <th>strand</th>\n",
       "      <th>phase</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>region</td>\n",
       "      <td>1</td>\n",
       "      <td>29903</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=NC_045512.2:1..29903;Dbxref=taxon:2697049;c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>five_prime_UTR</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-NC_045512.2:1..265;gbkey=5'UTR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>gene</td>\n",
       "      <td>266</td>\n",
       "      <td>21555</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=gene-GU280_gp01;Dbxref=GeneID:43740578;Name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>266</td>\n",
       "      <td>13468</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-YP_009724389.1;Parent=gene-GU280_gp01;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>13468</td>\n",
       "      <td>21555</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-YP_009724389.1;Parent=gene-GU280_gp01;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>266</td>\n",
       "      <td>805</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009724389.1:1..180;Note=nsp1%3B produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>806</td>\n",
       "      <td>2719</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009724389.1:181..818;Note=produced by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>2720</td>\n",
       "      <td>8554</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009724389.1:819..2763;Note=former nsp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>8555</td>\n",
       "      <td>10054</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009724389.1:2764..3263;Note=nsp4B_TM%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>10055</td>\n",
       "      <td>10972</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009724389.1:3264..3569;Note=nsp5A_3CL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>10973</td>\n",
       "      <td>11842</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009724389.1:3570..3859;Note=nsp6_TM%3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>11843</td>\n",
       "      <td>12091</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009724389.1:3860..3942;Note=produced ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>12092</td>\n",
       "      <td>12685</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009724389.1:3943..4140;Note=produced ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>12686</td>\n",
       "      <td>13024</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009724389.1:4141..4253;Note=ssRNA-bin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>13025</td>\n",
       "      <td>13441</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009724389.1:4254..4392;Note=nsp10_Cys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>13442</td>\n",
       "      <td>13468</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009724389.1:4393..5324;Note=nsp12%3B ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>13468</td>\n",
       "      <td>16236</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009724389.1:4393..5324;Note=nsp12%3B ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>16237</td>\n",
       "      <td>18039</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009724389.1:5325..5925;Note=nsp13_ZBD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>18040</td>\n",
       "      <td>19620</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009724389.1:5926..6452;Note=nsp14A2_E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>19621</td>\n",
       "      <td>20658</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009724389.1:6453..6798;Note=nsp15-A1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>20659</td>\n",
       "      <td>21552</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009724389.1:6799..7096;Note=nsp16_OMT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>266</td>\n",
       "      <td>13483</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-YP_009725295.1;Parent=gene-GU280_gp01;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>266</td>\n",
       "      <td>805</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009725295.1:1..180;Note=nsp1%3B produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>806</td>\n",
       "      <td>2719</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009725295.1:181..818;Note=produced by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>2720</td>\n",
       "      <td>8554</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009725295.1:819..2763;Note=former nsp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>8555</td>\n",
       "      <td>10054</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009725295.1:2764..3263;Note=nsp4B_TM%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>10055</td>\n",
       "      <td>10972</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009725295.1:3264..3569;Note=nsp5A_3CL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>10973</td>\n",
       "      <td>11842</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009725295.1:3570..3859;Note=nsp6_TM%3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>11843</td>\n",
       "      <td>12091</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009725295.1:3860..3942;Note=produced ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>12092</td>\n",
       "      <td>12685</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009725295.1:3943..4140;Note=produced ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>12686</td>\n",
       "      <td>13024</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009725295.1:4141..4253;Note=ssRNA-bin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>13025</td>\n",
       "      <td>13441</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009725295.1:4254..4392;Note=nsp10_Cys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>mature_protein_region_of_CDS</td>\n",
       "      <td>13442</td>\n",
       "      <td>13480</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-YP_009725295.1:4393..4405;Note=produced ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>stem_loop</td>\n",
       "      <td>13476</td>\n",
       "      <td>13503</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-GU280_gp01;Dbxref=GeneID:43740578;functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>stem_loop</td>\n",
       "      <td>13488</td>\n",
       "      <td>13542</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-GU280_gp01-2;Dbxref=GeneID:43740578;func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>gene</td>\n",
       "      <td>21563</td>\n",
       "      <td>25384</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=gene-GU280_gp02;Dbxref=GeneID:43740568;Name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>21563</td>\n",
       "      <td>25384</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-YP_009724390.1;Parent=gene-GU280_gp02;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>gene</td>\n",
       "      <td>25393</td>\n",
       "      <td>26220</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=gene-GU280_gp03;Dbxref=GeneID:43740569;Name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>25393</td>\n",
       "      <td>26220</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-YP_009724391.1;Parent=gene-GU280_gp03;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>gene</td>\n",
       "      <td>26245</td>\n",
       "      <td>26472</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=gene-GU280_gp04;Dbxref=GeneID:43740570;Name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>26245</td>\n",
       "      <td>26472</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-YP_009724392.1;Parent=gene-GU280_gp04;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>gene</td>\n",
       "      <td>26523</td>\n",
       "      <td>27191</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=gene-GU280_gp05;Dbxref=GeneID:43740571;Name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>26523</td>\n",
       "      <td>27191</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-YP_009724393.1;Parent=gene-GU280_gp05;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>gene</td>\n",
       "      <td>27202</td>\n",
       "      <td>27387</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=gene-GU280_gp06;Dbxref=GeneID:43740572;Name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>27202</td>\n",
       "      <td>27387</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-YP_009724394.1;Parent=gene-GU280_gp06;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>gene</td>\n",
       "      <td>27394</td>\n",
       "      <td>27759</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=gene-GU280_gp07;Dbxref=GeneID:43740573;Name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>27394</td>\n",
       "      <td>27759</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-YP_009724395.1;Parent=gene-GU280_gp07;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>gene</td>\n",
       "      <td>27756</td>\n",
       "      <td>27887</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=gene-GU280_gp08;Dbxref=GeneID:43740574;Name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>27756</td>\n",
       "      <td>27887</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-YP_009725318.1;Parent=gene-GU280_gp08;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>gene</td>\n",
       "      <td>27894</td>\n",
       "      <td>28259</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=gene-GU280_gp09;Dbxref=GeneID:43740577;Name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>27894</td>\n",
       "      <td>28259</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-YP_009724396.1;Parent=gene-GU280_gp09;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>gene</td>\n",
       "      <td>28274</td>\n",
       "      <td>29533</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=gene-GU280_gp10;Dbxref=GeneID:43740575;Name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>28274</td>\n",
       "      <td>29533</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-YP_009724397.2;Parent=gene-GU280_gp10;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>gene</td>\n",
       "      <td>29558</td>\n",
       "      <td>29674</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=gene-GU280_gp11;Dbxref=GeneID:43740576;Name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>29558</td>\n",
       "      <td>29674</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=cds-YP_009725255.1;Parent=gene-GU280_gp11;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>stem_loop</td>\n",
       "      <td>29609</td>\n",
       "      <td>29644</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-GU280_gp11;Dbxref=GeneID:43740576;functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>stem_loop</td>\n",
       "      <td>29629</td>\n",
       "      <td>29657</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-GU280_gp11-2;Dbxref=GeneID:43740576;func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>three_prime_UTR</td>\n",
       "      <td>29675</td>\n",
       "      <td>29903</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-NC_045512.2:29675..29903;gbkey=3'UTR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>stem_loop</td>\n",
       "      <td>29728</td>\n",
       "      <td>29768</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=id-NC_045512.2:29728..29768;Note=basepair e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          seqid  source                          type  start    end score  \\\n",
       "0   NC_045512.2  RefSeq                        region      1  29903     .   \n",
       "1   NC_045512.2  RefSeq                five_prime_UTR      1    265     .   \n",
       "2   NC_045512.2  RefSeq                          gene    266  21555     .   \n",
       "3   NC_045512.2  RefSeq                           CDS    266  13468     .   \n",
       "4   NC_045512.2  RefSeq                           CDS  13468  21555     .   \n",
       "5   NC_045512.2  RefSeq  mature_protein_region_of_CDS    266    805     .   \n",
       "6   NC_045512.2  RefSeq  mature_protein_region_of_CDS    806   2719     .   \n",
       "7   NC_045512.2  RefSeq  mature_protein_region_of_CDS   2720   8554     .   \n",
       "8   NC_045512.2  RefSeq  mature_protein_region_of_CDS   8555  10054     .   \n",
       "9   NC_045512.2  RefSeq  mature_protein_region_of_CDS  10055  10972     .   \n",
       "10  NC_045512.2  RefSeq  mature_protein_region_of_CDS  10973  11842     .   \n",
       "11  NC_045512.2  RefSeq  mature_protein_region_of_CDS  11843  12091     .   \n",
       "12  NC_045512.2  RefSeq  mature_protein_region_of_CDS  12092  12685     .   \n",
       "13  NC_045512.2  RefSeq  mature_protein_region_of_CDS  12686  13024     .   \n",
       "14  NC_045512.2  RefSeq  mature_protein_region_of_CDS  13025  13441     .   \n",
       "15  NC_045512.2  RefSeq  mature_protein_region_of_CDS  13442  13468     .   \n",
       "16  NC_045512.2  RefSeq  mature_protein_region_of_CDS  13468  16236     .   \n",
       "17  NC_045512.2  RefSeq  mature_protein_region_of_CDS  16237  18039     .   \n",
       "18  NC_045512.2  RefSeq  mature_protein_region_of_CDS  18040  19620     .   \n",
       "19  NC_045512.2  RefSeq  mature_protein_region_of_CDS  19621  20658     .   \n",
       "20  NC_045512.2  RefSeq  mature_protein_region_of_CDS  20659  21552     .   \n",
       "21  NC_045512.2  RefSeq                           CDS    266  13483     .   \n",
       "22  NC_045512.2  RefSeq  mature_protein_region_of_CDS    266    805     .   \n",
       "23  NC_045512.2  RefSeq  mature_protein_region_of_CDS    806   2719     .   \n",
       "24  NC_045512.2  RefSeq  mature_protein_region_of_CDS   2720   8554     .   \n",
       "25  NC_045512.2  RefSeq  mature_protein_region_of_CDS   8555  10054     .   \n",
       "26  NC_045512.2  RefSeq  mature_protein_region_of_CDS  10055  10972     .   \n",
       "27  NC_045512.2  RefSeq  mature_protein_region_of_CDS  10973  11842     .   \n",
       "28  NC_045512.2  RefSeq  mature_protein_region_of_CDS  11843  12091     .   \n",
       "29  NC_045512.2  RefSeq  mature_protein_region_of_CDS  12092  12685     .   \n",
       "30  NC_045512.2  RefSeq  mature_protein_region_of_CDS  12686  13024     .   \n",
       "31  NC_045512.2  RefSeq  mature_protein_region_of_CDS  13025  13441     .   \n",
       "32  NC_045512.2  RefSeq  mature_protein_region_of_CDS  13442  13480     .   \n",
       "33  NC_045512.2  RefSeq                     stem_loop  13476  13503     .   \n",
       "34  NC_045512.2  RefSeq                     stem_loop  13488  13542     .   \n",
       "35  NC_045512.2  RefSeq                          gene  21563  25384     .   \n",
       "36  NC_045512.2  RefSeq                           CDS  21563  25384     .   \n",
       "37  NC_045512.2  RefSeq                          gene  25393  26220     .   \n",
       "38  NC_045512.2  RefSeq                           CDS  25393  26220     .   \n",
       "39  NC_045512.2  RefSeq                          gene  26245  26472     .   \n",
       "40  NC_045512.2  RefSeq                           CDS  26245  26472     .   \n",
       "41  NC_045512.2  RefSeq                          gene  26523  27191     .   \n",
       "42  NC_045512.2  RefSeq                           CDS  26523  27191     .   \n",
       "43  NC_045512.2  RefSeq                          gene  27202  27387     .   \n",
       "44  NC_045512.2  RefSeq                           CDS  27202  27387     .   \n",
       "45  NC_045512.2  RefSeq                          gene  27394  27759     .   \n",
       "46  NC_045512.2  RefSeq                           CDS  27394  27759     .   \n",
       "47  NC_045512.2  RefSeq                          gene  27756  27887     .   \n",
       "48  NC_045512.2  RefSeq                           CDS  27756  27887     .   \n",
       "49  NC_045512.2  RefSeq                          gene  27894  28259     .   \n",
       "50  NC_045512.2  RefSeq                           CDS  27894  28259     .   \n",
       "51  NC_045512.2  RefSeq                          gene  28274  29533     .   \n",
       "52  NC_045512.2  RefSeq                           CDS  28274  29533     .   \n",
       "53  NC_045512.2  RefSeq                          gene  29558  29674     .   \n",
       "54  NC_045512.2  RefSeq                           CDS  29558  29674     .   \n",
       "55  NC_045512.2  RefSeq                     stem_loop  29609  29644     .   \n",
       "56  NC_045512.2  RefSeq                     stem_loop  29629  29657     .   \n",
       "57  NC_045512.2  RefSeq               three_prime_UTR  29675  29903     .   \n",
       "58  NC_045512.2  RefSeq                     stem_loop  29728  29768     .   \n",
       "\n",
       "   strand phase                                         attributes  \n",
       "0       +     .  ID=NC_045512.2:1..29903;Dbxref=taxon:2697049;c...  \n",
       "1       +     .               ID=id-NC_045512.2:1..265;gbkey=5'UTR  \n",
       "2       +     .  ID=gene-GU280_gp01;Dbxref=GeneID:43740578;Name...  \n",
       "3       +     0  ID=cds-YP_009724389.1;Parent=gene-GU280_gp01;D...  \n",
       "4       +     0  ID=cds-YP_009724389.1;Parent=gene-GU280_gp01;D...  \n",
       "5       +     .  ID=id-YP_009724389.1:1..180;Note=nsp1%3B produ...  \n",
       "6       +     .  ID=id-YP_009724389.1:181..818;Note=produced by...  \n",
       "7       +     .  ID=id-YP_009724389.1:819..2763;Note=former nsp...  \n",
       "8       +     .  ID=id-YP_009724389.1:2764..3263;Note=nsp4B_TM%...  \n",
       "9       +     .  ID=id-YP_009724389.1:3264..3569;Note=nsp5A_3CL...  \n",
       "10      +     .  ID=id-YP_009724389.1:3570..3859;Note=nsp6_TM%3...  \n",
       "11      +     .  ID=id-YP_009724389.1:3860..3942;Note=produced ...  \n",
       "12      +     .  ID=id-YP_009724389.1:3943..4140;Note=produced ...  \n",
       "13      +     .  ID=id-YP_009724389.1:4141..4253;Note=ssRNA-bin...  \n",
       "14      +     .  ID=id-YP_009724389.1:4254..4392;Note=nsp10_Cys...  \n",
       "15      +     .  ID=id-YP_009724389.1:4393..5324;Note=nsp12%3B ...  \n",
       "16      +     .  ID=id-YP_009724389.1:4393..5324;Note=nsp12%3B ...  \n",
       "17      +     .  ID=id-YP_009724389.1:5325..5925;Note=nsp13_ZBD...  \n",
       "18      +     .  ID=id-YP_009724389.1:5926..6452;Note=nsp14A2_E...  \n",
       "19      +     .  ID=id-YP_009724389.1:6453..6798;Note=nsp15-A1 ...  \n",
       "20      +     .  ID=id-YP_009724389.1:6799..7096;Note=nsp16_OMT...  \n",
       "21      +     0  ID=cds-YP_009725295.1;Parent=gene-GU280_gp01;D...  \n",
       "22      +     .  ID=id-YP_009725295.1:1..180;Note=nsp1%3B produ...  \n",
       "23      +     .  ID=id-YP_009725295.1:181..818;Note=produced by...  \n",
       "24      +     .  ID=id-YP_009725295.1:819..2763;Note=former nsp...  \n",
       "25      +     .  ID=id-YP_009725295.1:2764..3263;Note=nsp4B_TM%...  \n",
       "26      +     .  ID=id-YP_009725295.1:3264..3569;Note=nsp5A_3CL...  \n",
       "27      +     .  ID=id-YP_009725295.1:3570..3859;Note=nsp6_TM%3...  \n",
       "28      +     .  ID=id-YP_009725295.1:3860..3942;Note=produced ...  \n",
       "29      +     .  ID=id-YP_009725295.1:3943..4140;Note=produced ...  \n",
       "30      +     .  ID=id-YP_009725295.1:4141..4253;Note=ssRNA-bin...  \n",
       "31      +     .  ID=id-YP_009725295.1:4254..4392;Note=nsp10_Cys...  \n",
       "32      +     .  ID=id-YP_009725295.1:4393..4405;Note=produced ...  \n",
       "33      +     .  ID=id-GU280_gp01;Dbxref=GeneID:43740578;functi...  \n",
       "34      +     .  ID=id-GU280_gp01-2;Dbxref=GeneID:43740578;func...  \n",
       "35      +     .  ID=gene-GU280_gp02;Dbxref=GeneID:43740568;Name...  \n",
       "36      +     0  ID=cds-YP_009724390.1;Parent=gene-GU280_gp02;D...  \n",
       "37      +     .  ID=gene-GU280_gp03;Dbxref=GeneID:43740569;Name...  \n",
       "38      +     0  ID=cds-YP_009724391.1;Parent=gene-GU280_gp03;D...  \n",
       "39      +     .  ID=gene-GU280_gp04;Dbxref=GeneID:43740570;Name...  \n",
       "40      +     0  ID=cds-YP_009724392.1;Parent=gene-GU280_gp04;D...  \n",
       "41      +     .  ID=gene-GU280_gp05;Dbxref=GeneID:43740571;Name...  \n",
       "42      +     0  ID=cds-YP_009724393.1;Parent=gene-GU280_gp05;D...  \n",
       "43      +     .  ID=gene-GU280_gp06;Dbxref=GeneID:43740572;Name...  \n",
       "44      +     0  ID=cds-YP_009724394.1;Parent=gene-GU280_gp06;D...  \n",
       "45      +     .  ID=gene-GU280_gp07;Dbxref=GeneID:43740573;Name...  \n",
       "46      +     0  ID=cds-YP_009724395.1;Parent=gene-GU280_gp07;D...  \n",
       "47      +     .  ID=gene-GU280_gp08;Dbxref=GeneID:43740574;Name...  \n",
       "48      +     0  ID=cds-YP_009725318.1;Parent=gene-GU280_gp08;D...  \n",
       "49      +     .  ID=gene-GU280_gp09;Dbxref=GeneID:43740577;Name...  \n",
       "50      +     0  ID=cds-YP_009724396.1;Parent=gene-GU280_gp09;D...  \n",
       "51      +     .  ID=gene-GU280_gp10;Dbxref=GeneID:43740575;Name...  \n",
       "52      +     0  ID=cds-YP_009724397.2;Parent=gene-GU280_gp10;D...  \n",
       "53      +     .  ID=gene-GU280_gp11;Dbxref=GeneID:43740576;Name...  \n",
       "54      +     0  ID=cds-YP_009725255.1;Parent=gene-GU280_gp11;D...  \n",
       "55      +     .  ID=id-GU280_gp11;Dbxref=GeneID:43740576;functi...  \n",
       "56      +     .  ID=id-GU280_gp11-2;Dbxref=GeneID:43740576;func...  \n",
       "57      +     .         ID=id-NC_045512.2:29675..29903;gbkey=3'UTR  \n",
       "58      +     .  ID=id-NC_045512.2:29728..29768;Note=basepair e...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_anotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0314ddf3-35e1-4673-8f7a-22446f948063",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_anotations.sort_values('start')\n",
    "def string2dict(s, sep = ';'):\n",
    "    r = {}\n",
    "    for i in s.split(sep):\n",
    "        key, value = i.split('=')\n",
    "        r[key] = value\n",
    "    return r\n",
    "#gene_anotations['att'] = gene_anotations['attributes'].apply(string2dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c602a078-2b7e-449c-91fc-3927c889b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_anotations = pd.concat([gene_anotations.drop(['attributes'], axis=1), gene_anotations['attributes'].apply(lambda x: pd.Series(string2dict(x)))], axis=1).drop(['gene_biotype','product' ,'protein_id','Note','exception','locus_tag','function','inference','gene_synonym', 'Dbxref', 'collection-date', 'country', 'gb-acronym', 'gbkey', 'genome', 'isolate', 'mol_type', 'nat-host', 'old-name', 'Name'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45c1e984-ff8d-45a8-be7d-d96a7972d6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqid</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>score</th>\n",
       "      <th>strand</th>\n",
       "      <th>phase</th>\n",
       "      <th>ID</th>\n",
       "      <th>gene</th>\n",
       "      <th>Parent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>266</td>\n",
       "      <td>13468</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>cds-YP_009724389.1</td>\n",
       "      <td>ORF1ab</td>\n",
       "      <td>gene-GU280_gp01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>266</td>\n",
       "      <td>13483</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>cds-YP_009725295.1</td>\n",
       "      <td>ORF1ab</td>\n",
       "      <td>gene-GU280_gp01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>13468</td>\n",
       "      <td>21555</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>cds-YP_009724389.1</td>\n",
       "      <td>ORF1ab</td>\n",
       "      <td>gene-GU280_gp01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>21563</td>\n",
       "      <td>25384</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>cds-YP_009724390.1</td>\n",
       "      <td>S</td>\n",
       "      <td>gene-GU280_gp02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>25393</td>\n",
       "      <td>26220</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>cds-YP_009724391.1</td>\n",
       "      <td>ORF3a</td>\n",
       "      <td>gene-GU280_gp03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>26245</td>\n",
       "      <td>26472</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>cds-YP_009724392.1</td>\n",
       "      <td>E</td>\n",
       "      <td>gene-GU280_gp04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>26523</td>\n",
       "      <td>27191</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>cds-YP_009724393.1</td>\n",
       "      <td>M</td>\n",
       "      <td>gene-GU280_gp05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>27202</td>\n",
       "      <td>27387</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>cds-YP_009724394.1</td>\n",
       "      <td>ORF6</td>\n",
       "      <td>gene-GU280_gp06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>27394</td>\n",
       "      <td>27759</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>cds-YP_009724395.1</td>\n",
       "      <td>ORF7a</td>\n",
       "      <td>gene-GU280_gp07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>27756</td>\n",
       "      <td>27887</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>cds-YP_009725318.1</td>\n",
       "      <td>ORF7b</td>\n",
       "      <td>gene-GU280_gp08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>27894</td>\n",
       "      <td>28259</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>cds-YP_009724396.1</td>\n",
       "      <td>ORF8</td>\n",
       "      <td>gene-GU280_gp09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>28274</td>\n",
       "      <td>29533</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>cds-YP_009724397.2</td>\n",
       "      <td>N</td>\n",
       "      <td>gene-GU280_gp10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>NC_045512.2</td>\n",
       "      <td>RefSeq</td>\n",
       "      <td>CDS</td>\n",
       "      <td>29558</td>\n",
       "      <td>29674</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>cds-YP_009725255.1</td>\n",
       "      <td>ORF10</td>\n",
       "      <td>gene-GU280_gp11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          seqid  source type  start    end score strand phase  \\\n",
       "3   NC_045512.2  RefSeq  CDS    266  13468     .      +     0   \n",
       "21  NC_045512.2  RefSeq  CDS    266  13483     .      +     0   \n",
       "4   NC_045512.2  RefSeq  CDS  13468  21555     .      +     0   \n",
       "36  NC_045512.2  RefSeq  CDS  21563  25384     .      +     0   \n",
       "38  NC_045512.2  RefSeq  CDS  25393  26220     .      +     0   \n",
       "40  NC_045512.2  RefSeq  CDS  26245  26472     .      +     0   \n",
       "42  NC_045512.2  RefSeq  CDS  26523  27191     .      +     0   \n",
       "44  NC_045512.2  RefSeq  CDS  27202  27387     .      +     0   \n",
       "46  NC_045512.2  RefSeq  CDS  27394  27759     .      +     0   \n",
       "48  NC_045512.2  RefSeq  CDS  27756  27887     .      +     0   \n",
       "50  NC_045512.2  RefSeq  CDS  27894  28259     .      +     0   \n",
       "52  NC_045512.2  RefSeq  CDS  28274  29533     .      +     0   \n",
       "54  NC_045512.2  RefSeq  CDS  29558  29674     .      +     0   \n",
       "\n",
       "                    ID    gene           Parent  \n",
       "3   cds-YP_009724389.1  ORF1ab  gene-GU280_gp01  \n",
       "21  cds-YP_009725295.1  ORF1ab  gene-GU280_gp01  \n",
       "4   cds-YP_009724389.1  ORF1ab  gene-GU280_gp01  \n",
       "36  cds-YP_009724390.1       S  gene-GU280_gp02  \n",
       "38  cds-YP_009724391.1   ORF3a  gene-GU280_gp03  \n",
       "40  cds-YP_009724392.1       E  gene-GU280_gp04  \n",
       "42  cds-YP_009724393.1       M  gene-GU280_gp05  \n",
       "44  cds-YP_009724394.1    ORF6  gene-GU280_gp06  \n",
       "46  cds-YP_009724395.1   ORF7a  gene-GU280_gp07  \n",
       "48  cds-YP_009725318.1   ORF7b  gene-GU280_gp08  \n",
       "50  cds-YP_009724396.1    ORF8  gene-GU280_gp09  \n",
       "52  cds-YP_009724397.2       N  gene-GU280_gp10  \n",
       "54  cds-YP_009725255.1   ORF10  gene-GU280_gp11  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_anotations.query('type == \"CDS\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbbb9f3b-6ded-4640-a5a0-15002e692cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_anotations = gene_anotations.dropna().sort_values('start')#.iloc[1:].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43e93867-11f8-40c0-a464-7e768510107a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seqid': {3: 'NC_045512.2',\n",
       "  21: 'NC_045512.2',\n",
       "  4: 'NC_045512.2',\n",
       "  36: 'NC_045512.2',\n",
       "  38: 'NC_045512.2',\n",
       "  40: 'NC_045512.2',\n",
       "  42: 'NC_045512.2',\n",
       "  44: 'NC_045512.2',\n",
       "  46: 'NC_045512.2',\n",
       "  48: 'NC_045512.2',\n",
       "  50: 'NC_045512.2',\n",
       "  52: 'NC_045512.2',\n",
       "  54: 'NC_045512.2'},\n",
       " 'source': {3: 'RefSeq',\n",
       "  21: 'RefSeq',\n",
       "  4: 'RefSeq',\n",
       "  36: 'RefSeq',\n",
       "  38: 'RefSeq',\n",
       "  40: 'RefSeq',\n",
       "  42: 'RefSeq',\n",
       "  44: 'RefSeq',\n",
       "  46: 'RefSeq',\n",
       "  48: 'RefSeq',\n",
       "  50: 'RefSeq',\n",
       "  52: 'RefSeq',\n",
       "  54: 'RefSeq'},\n",
       " 'type': {3: 'CDS',\n",
       "  21: 'CDS',\n",
       "  4: 'CDS',\n",
       "  36: 'CDS',\n",
       "  38: 'CDS',\n",
       "  40: 'CDS',\n",
       "  42: 'CDS',\n",
       "  44: 'CDS',\n",
       "  46: 'CDS',\n",
       "  48: 'CDS',\n",
       "  50: 'CDS',\n",
       "  52: 'CDS',\n",
       "  54: 'CDS'},\n",
       " 'start': {3: 266,\n",
       "  21: 266,\n",
       "  4: 13468,\n",
       "  36: 21563,\n",
       "  38: 25393,\n",
       "  40: 26245,\n",
       "  42: 26523,\n",
       "  44: 27202,\n",
       "  46: 27394,\n",
       "  48: 27756,\n",
       "  50: 27894,\n",
       "  52: 28274,\n",
       "  54: 29558},\n",
       " 'end': {3: 13468,\n",
       "  21: 13483,\n",
       "  4: 21555,\n",
       "  36: 25384,\n",
       "  38: 26220,\n",
       "  40: 26472,\n",
       "  42: 27191,\n",
       "  44: 27387,\n",
       "  46: 27759,\n",
       "  48: 27887,\n",
       "  50: 28259,\n",
       "  52: 29533,\n",
       "  54: 29674},\n",
       " 'score': {3: '.',\n",
       "  21: '.',\n",
       "  4: '.',\n",
       "  36: '.',\n",
       "  38: '.',\n",
       "  40: '.',\n",
       "  42: '.',\n",
       "  44: '.',\n",
       "  46: '.',\n",
       "  48: '.',\n",
       "  50: '.',\n",
       "  52: '.',\n",
       "  54: '.'},\n",
       " 'strand': {3: '+',\n",
       "  21: '+',\n",
       "  4: '+',\n",
       "  36: '+',\n",
       "  38: '+',\n",
       "  40: '+',\n",
       "  42: '+',\n",
       "  44: '+',\n",
       "  46: '+',\n",
       "  48: '+',\n",
       "  50: '+',\n",
       "  52: '+',\n",
       "  54: '+'},\n",
       " 'phase': {3: '0',\n",
       "  21: '0',\n",
       "  4: '0',\n",
       "  36: '0',\n",
       "  38: '0',\n",
       "  40: '0',\n",
       "  42: '0',\n",
       "  44: '0',\n",
       "  46: '0',\n",
       "  48: '0',\n",
       "  50: '0',\n",
       "  52: '0',\n",
       "  54: '0'},\n",
       " 'ID': {3: 'cds-YP_009724389.1',\n",
       "  21: 'cds-YP_009725295.1',\n",
       "  4: 'cds-YP_009724389.1',\n",
       "  36: 'cds-YP_009724390.1',\n",
       "  38: 'cds-YP_009724391.1',\n",
       "  40: 'cds-YP_009724392.1',\n",
       "  42: 'cds-YP_009724393.1',\n",
       "  44: 'cds-YP_009724394.1',\n",
       "  46: 'cds-YP_009724395.1',\n",
       "  48: 'cds-YP_009725318.1',\n",
       "  50: 'cds-YP_009724396.1',\n",
       "  52: 'cds-YP_009724397.2',\n",
       "  54: 'cds-YP_009725255.1'},\n",
       " 'gene': {3: 'ORF1ab',\n",
       "  21: 'ORF1ab',\n",
       "  4: 'ORF1ab',\n",
       "  36: 'S',\n",
       "  38: 'ORF3a',\n",
       "  40: 'E',\n",
       "  42: 'M',\n",
       "  44: 'ORF6',\n",
       "  46: 'ORF7a',\n",
       "  48: 'ORF7b',\n",
       "  50: 'ORF8',\n",
       "  52: 'N',\n",
       "  54: 'ORF10'},\n",
       " 'Parent': {3: 'gene-GU280_gp01',\n",
       "  21: 'gene-GU280_gp01',\n",
       "  4: 'gene-GU280_gp01',\n",
       "  36: 'gene-GU280_gp02',\n",
       "  38: 'gene-GU280_gp03',\n",
       "  40: 'gene-GU280_gp04',\n",
       "  42: 'gene-GU280_gp05',\n",
       "  44: 'gene-GU280_gp06',\n",
       "  46: 'gene-GU280_gp07',\n",
       "  48: 'gene-GU280_gp08',\n",
       "  50: 'gene-GU280_gp09',\n",
       "  52: 'gene-GU280_gp10',\n",
       "  54: 'gene-GU280_gp11'}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_anotations.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dde94c5d-92ba-4add-a096-c3a651343d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ORF1ab', 'CDS']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_anotations.query('start < 270 and end > 270').loc[0,['gene', 'type']].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdca062e-3cf6-498a-a624-3fa2e7ad2395",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "dataset = pd.read_csv('public.minAf.01.vcf.gz', compression = 'gzip', comment = '#' , delim_whitespace=True, header=None,names = get_vcf_names('public.minAf.01.vcf.gz')) \n",
    "dataset.index = dataset.ID\n",
    "datasetT = dataset.T.iloc[9:].reset_index()\n",
    "datasetT['index']\n",
    "datasetT = pd.concat([datasetT['index'].str.split(r'\\||/',expand=True).add_prefix('label_'), datasetT.iloc[:,1:]], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e2186f-2758-4d19-9d70-200efa85bab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7dfc81-0f65-470a-a167-9af4cbc16573",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.index = dataset.ID\n",
    "datasetT = dataset.T.iloc[9:].reset_index()\n",
    "datasetT['index']\n",
    "datasetT = pd.concat([datasetT['index'].str.split(r'\\||/',expand=True).add_prefix('label_'), datasetT.iloc[:,1:]], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d91c90-5914-4e98-9b86-4cc663a4be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetT.iloc[:,7:-1]\n",
    "\n",
    "\n",
    "#dataset['label'] = dataset.iloc[:, 9:].idxmax(1)\n",
    "#dataset = dataset[list(dataset.columns[:9]) + ['label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0210b1d-587a-4d5a-9cbc-41106394a397",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetT['date'] =datasetT.label_6.apply(lambda x: pd.to_datetime(x, format='%y-%m-%d',errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba76d734-ec3c-494e-bf74-a69d51115644",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetT[pd.notnull(datasetT['date'])].to_csv('mutation_panel_vcf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f379fe80-2329-4f24-b2e0-8aaad8ac39b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetresem = datasetT.copy()\n",
    "datasetresem =datasetresem.set_index('date') \n",
    "#datasetresem =datasetresem.resample('1d').mean().dropna().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187fde55-a185-464f-aca5-719407b8d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetresem.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb8304e-4e46-4ef0-8788-7375a295fcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "%time transformed = UMAP().fit_transform(datasetT.iloc[1000:5000,7:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2c4445-dbca-4c5a-a1e9-fb3ea5c17206",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(pd.DataFrame(transformed, columns= ['umap1', 'umap2']), x = 'umap1', y ='umap2' )\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=1000,\n",
    "    height=1000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f15308c-b081-44c7-81be-6f429169e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetT.iloc[:100,7:-1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a42cf1-00e1-461f-a83f-a8f0b144edca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(datasetT.iloc[:100,7:-1].astype(int), figsize=(15, 15),cmap = sns.diverging_palette(220, 20, as_cmap=True),col_cluster=False) #\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8e3387-1770-4766-b43f-3b8fd80121b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e4a8f0-2d52-45d0-90f5-34f740ac618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustergram = dashbio.Clustergram(\n",
    "    data=datasetT.iloc[:2000,7:-1].astype(int).values,\n",
    "    row_labels=list(datasetT.index[:100]),\n",
    "    column_labels=list(datasetT.columns[:100]),\n",
    "    cluster = 'row',)\n",
    "clustergram.update_layout(\n",
    "    autosize=False,\n",
    "    width=1000,\n",
    "    height=1000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712d9b81-3e7f-4eb8-a05b-40f94227e714",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.astype({col:int for col in df.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48af248-9236-40a8-81cd-36eae2b91db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import plotly.graph_objs as go\n",
    "#from plotly.subplots import make_subplots\n",
    "#fig = make_subplots(rows=2)\n",
    "#fig.add_trace( go.Scatter(x=list(range(df.shape[1])),\n",
    "#                          y=[1 for x in range(df.shape[1])]),  row=1, col=1)\n",
    "#fig.add_trace( dashbio.Clustergram(\n",
    "#    data=df.loc[list(df.index)].values,\n",
    "#    row_labels=list(df.index),\n",
    "#    column_labels=list(df.columns),\n",
    "#    cluster = 'row',), row=2, col=1)\n",
    "\n",
    "\n",
    "#fig.update_layout(\n",
    "#    autosize=False,\n",
    "#    width=1000,\n",
    "#    height=1000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1127cc11-01e4-4aee-bfc7-43c46e49c7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba2cc1e-5785-448c-b127-daa87504fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import six.moves.urllib.request as urlreq\n",
    "\n",
    "# read in JSON\n",
    "sourcered = urlreq.urlopen('https://raw.githubusercontent.com/plotly/dash-bio-docs-files/master/pileup.features.ga4gh.chr1.120000-125000.chr17.7500000-7515100.json').read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd366059-84f4-4f52-9d77-79de26f996c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcered[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63369ac0-c1f5-4bfa-bdfe-5e803fbd1405",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetT.C29784T.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d8382-ff74-4884-b3b9-3d0f240a3b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mutation_list import clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd8c687-520e-409a-9b5a-b97ad9ee6caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_data = pd.DataFrame(clusters).T\n",
    "genome_data = genome_data[pd.notnull(genome_data.who_name) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43bcbd8-e2f7-46df-909f-92b32a569f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_data.mutations.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657d0fc9-ecc2-494b-8128-eda389e6b37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string2dict2(s, sep = ',', intro = ''):\n",
    "    r = {}\n",
    "    try:\n",
    "        for i in s.split(sep):\n",
    "            r[intro+i] = 1\n",
    "    except: return r\n",
    "    return r\n",
    "\n",
    "aa = pd.read_csv('nextclade.csv', sep = ';')#.query('\"qc.overallStatus\" == \"good\"')\n",
    "aa2 = pd.concat([aa['seqName'].str.split(r'\\||/',expand=True).add_prefix('label_'), \n",
    "                 #aa['attributes'].apply(lambda x: pd.Series(string2dict2(x, intro = 'seqname_'))),\n",
    "                 aa['substitutions'].apply(lambda x: pd.Series(string2dict2(x,  intro = 'substitutions_'))).fillna(0).astype(int), \n",
    "                 aa['deletions'].apply(lambda x: pd.Series(string2dict2(x, intro = 'deletions_'))).fillna(0).astype(int), \n",
    "                 aa['insertions'].apply(lambda x: pd.Series(string2dict2(x,  intro = 'insertions_'))).fillna(0).astype(int), \n",
    "                 aa['aaSubstitutions'].apply(lambda x: pd.Series(string2dict2(x,  intro = 'aaSubstitutions_'))).fillna(0).astype(int), \n",
    "                 aa['aaDeletions'].apply(lambda x: pd.Series(string2dict2(x,  intro = 'aaDeletions_'))).fillna(0).astype(int), \n",
    "                 aa.drop(['seqName', 'substitutions', 'deletions', 'insertions', 'aaSubstitutions', 'aaDeletions'],axis = 'columns') ],axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb70c83-a16b-4aa7-b4e9-868a003266f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa2#['substitutions'].apply(lambda x: pd.Series(string2dict2(x,  intro = 'substitutions_'))).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5070f46a-482f-40bf-9a70-c61d42933670",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa2[aa2['qc.overallStatus'] == 'good'].dropna(axis = 1).to_csv('spreadNextCladeDataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e0ec48-bf30-4ebf-a131-dc3fd59b72a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38e2f1b-768a-4936-b6d3-7443dcf397b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4c02e6c-41eb-4f14-9a8c-ea6bfd2fe90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfnaa = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/plotly/dash-bio-docs-files/master/' +\n",
    "    'manhattan_data.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "193ea803-e64f-4732-b077-c60701e9b792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHR</th>\n",
       "      <th>BP</th>\n",
       "      <th>P</th>\n",
       "      <th>SNP</th>\n",
       "      <th>ZSCORE</th>\n",
       "      <th>EFFECTSIZE</th>\n",
       "      <th>GENE</th>\n",
       "      <th>DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>937641</td>\n",
       "      <td>0.335344</td>\n",
       "      <td>rs9697358</td>\n",
       "      <td>0.9634</td>\n",
       "      <td>-0.0946</td>\n",
       "      <td>ISG15</td>\n",
       "      <td>1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1136887</td>\n",
       "      <td>0.245857</td>\n",
       "      <td>rs34945898</td>\n",
       "      <td>1.1605</td>\n",
       "      <td>-0.0947</td>\n",
       "      <td>TNFRSF4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2116240</td>\n",
       "      <td>0.823286</td>\n",
       "      <td>rs12034613</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>-0.0741</td>\n",
       "      <td>FP7162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2310562</td>\n",
       "      <td>0.493204</td>\n",
       "      <td>rs4648633</td>\n",
       "      <td>0.6852</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>MORN1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2681715</td>\n",
       "      <td>0.605392</td>\n",
       "      <td>rs4430271</td>\n",
       "      <td>0.5167</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>MMEL1</td>\n",
       "      <td>127427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14407</th>\n",
       "      <td>23</td>\n",
       "      <td>153207974</td>\n",
       "      <td>0.574920</td>\n",
       "      <td>rs766418</td>\n",
       "      <td>0.5608</td>\n",
       "      <td>-0.0190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14408</th>\n",
       "      <td>23</td>\n",
       "      <td>153280339</td>\n",
       "      <td>0.978400</td>\n",
       "      <td>rs11593</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>-0.1355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14409</th>\n",
       "      <td>23</td>\n",
       "      <td>153546061</td>\n",
       "      <td>0.056012</td>\n",
       "      <td>rs5987005</td>\n",
       "      <td>1.9109</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14410</th>\n",
       "      <td>23</td>\n",
       "      <td>153903746</td>\n",
       "      <td>0.132189</td>\n",
       "      <td>rs28370194</td>\n",
       "      <td>1.5055</td>\n",
       "      <td>-0.1425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14411</th>\n",
       "      <td>23</td>\n",
       "      <td>154208789</td>\n",
       "      <td>0.497909</td>\n",
       "      <td>rs524609</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.2542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14412 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CHR         BP         P         SNP  ZSCORE  EFFECTSIZE     GENE  \\\n",
       "0        1     937641  0.335344   rs9697358  0.9634     -0.0946    ISG15   \n",
       "1        1    1136887  0.245857  rs34945898  1.1605     -0.0947  TNFRSF4   \n",
       "2        1    2116240  0.823286  rs12034613  0.2233     -0.0741   FP7162   \n",
       "3        1    2310562  0.493204   rs4648633  0.6852      0.0146    MORN1   \n",
       "4        1    2681715  0.605392   rs4430271  0.5167      0.1234    MMEL1   \n",
       "...    ...        ...       ...         ...     ...         ...      ...   \n",
       "14407   23  153207974  0.574920    rs766418  0.5608     -0.0190      NaN   \n",
       "14408   23  153280339  0.978400     rs11593  0.0271     -0.1355      NaN   \n",
       "14409   23  153546061  0.056012   rs5987005  1.9109      0.0026      NaN   \n",
       "14410   23  153903746  0.132189  rs28370194  1.5055     -0.1425      NaN   \n",
       "14411   23  154208789  0.497909    rs524609  0.6778      0.2542      NaN   \n",
       "\n",
       "       DISTANCE  \n",
       "0          1068  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4        127427  \n",
       "...         ...  \n",
       "14407        -1  \n",
       "14408        -1  \n",
       "14409        -1  \n",
       "14410        -1  \n",
       "14411        -1  \n",
       "\n",
       "[14412 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbe3387-e564-4a1c-94d9-27d1bb8c0795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:CoViewer]",
   "language": "python",
   "name": "conda-env-CoViewer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
