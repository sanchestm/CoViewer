{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d701964b-8237-4341-a38f-fb108c6dc914",
   "metadata": {},
   "source": [
    "# Genome Visualization data organizer + plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a99347-831d-4709-98ea-d9493aae6598",
   "metadata": {},
   "source": [
    "#### This file has the goal to help users rearange Sars-Cov-2 Genomic Data preprocessed by NextStrain and return it in a CSV format that can be easily read by common data vizualization software. For geographical data we suggest Kepler.gl, for other plots we suggest using excel or plotly chart studio. This notebook has been tested in a small dataset. It is not guaranteed to work in every scenario\n",
    "\n",
    "### for this example we downloaded data from:\n",
    "https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/virus?SeqType_s=Nucleotide&VirusLineage_ss=Severe%20acute%20respiratory%20syndrome%20coronavirus%202%20(SARS-CoV-2),%20taxid:2697049&CollectionDate_dr=1950-01-01T00:00:00Z%20TO%20NOW&CreateDate_dt=1950-01-01T00:00:00Z%20TO%20NOW\n",
    "### then we preprocessed this genomes with next strain next clade\n",
    "https://clades.nextstrain.org/results\n",
    "### last we downloaded the results as a CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f7aad-61ee-4b2f-a0dd-c242f8702aeb",
   "metadata": {},
   "source": [
    "### Imports (packages that we will be using in our example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8283bb7d-1f32-4825-a681-fc81810ae452",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import plotly.express as px\n",
    "from ipywidgets import interact, interact_manual, interactive,interactive_output, Layout\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "import re\n",
    "import umap\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.model_selection import cross_val_score,train_test_split, GridSearchCV\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import shap\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from scipy.sparse import coo_matrix\n",
    "import hdbscan\n",
    "from datashader.bundling import hammer_bundle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "### see https://docs.nextstrain.org/projects/nextclade/en/latest/user/algorithm/05-phylogenetic-placement.html for equation\n",
    "@nb.njit()\n",
    "def nextstrain_metric(ref,query):\n",
    "    return ref.sum() + query.sum() - (ref == query).sum() - len(ref)\n",
    "\n",
    "layout = widgets.Layout(width='75%')\n",
    "\n",
    "def string2dict2(s, sep = ',', intro = ''):\n",
    "    r = {}\n",
    "    try:\n",
    "        for i in s.split(sep):\n",
    "            r[intro+i] = 1\n",
    "    except: return r\n",
    "    return r\n",
    "\n",
    "def getpos(location):\n",
    "    try: \n",
    "        return [float(country_loc[location].y), float(country_loc[location].x)]\n",
    "    except:\n",
    "        return [0.0,0.0]\n",
    "\n",
    "gene_anotations = pd.DataFrame({\n",
    " 'seqid': {0: 'NC_045512.2',  1: 'NC_045512.2',  2: 'NC_045512.2',  3: 'NC_045512.2',  4: 'NC_045512.2',  5: 'NC_045512.2',  6: 'NC_045512.2',  7: 'NC_045512.2',  8: 'NC_045512.2',\n",
    "  9: 'NC_045512.2',  10: 'NC_045512.2', 11:'NC_045512.2' },\n",
    " 'source': {0: 'RefSeq',  1: 'RefSeq',  2: 'RefSeq',  3: 'RefSeq',  4: 'RefSeq',  5: 'RefSeq',  6: 'RefSeq',  7: 'RefSeq',  8: 'RefSeq',  9: 'RefSeq',  10: 'RefSeq', 11: 'RefSeq'},\n",
    " 'type': {0: 'CDS',  1: 'CDS',  2: 'CDS',  3: 'CDS',  4: 'CDS',  5: 'CDS',  6: 'CDS',  7: 'CDS',  8: 'CDS',  9: 'CDS',  10: 'CDS', 11: 'CDS'},\n",
    " 'start': {0: 266,  1: 21563,  2: 25393,  3: 26245,  4: 26523,  5: 27202,  6: 27394,  7: 27756,  8: 27894,  9: 28274,  10: 29558, 11: 13468}, \n",
    " 'end': {0: 13468,  1: 25384,  2: 26220,  3: 26472,  4: 27191,  5: 27387,  6: 27759,  7: 27887,  8: 28259,  9: 29533,  10: 29674, 11: 21555},\n",
    " 'ID': {0: 'cds-YP_009724389.1',  1: 'cds-YP_009724390.1',  2: 'cds-YP_009724391.1',  3: 'cds-YP_009724392.1',  4: 'cds-YP_009724393.1',  5: 'cds-YP_009724394.1',\n",
    "        6: 'cds-YP_009724395.1',  7: 'cds-YP_009725318.1',  8: 'cds-YP_009724396.1',  9: 'cds-YP_009724397.2',  10: 'cds-YP_009725255.1', 11:'cds-YP_009724389.1'},\n",
    " 'gene': {0: 'ORF1a',  1: 'S',  2: 'ORF3a',  3: 'E',  4: 'M',  5: 'ORF6',  6: 'ORF7a',  7: 'ORF7b',  8: 'ORF8',  9: 'N',  10: 'ORF10', 11: 'ORF1b'}}).sort_values('start').reset_index().drop('index', axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe73207-a5b0-40dd-a3ff-909c12cbb4c6",
   "metadata": {},
   "source": [
    "### Open data from Nextstrain\n",
    "The first step is open the CSV file that we downloaded from next strain. After opening we keep only the data which has good overall status for quality control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2be5ee5-2209-4df5-882d-edd6109511df",
   "metadata": {},
   "outputs": [],
   "source": [
    "### this line opens the file nextcladeAsia.csv, to run your own data change this name and remember to first add the dataset to the folder of this notebook\n",
    "genome_table = pd.read_csv('nextcladeAsia.csv', sep = ';')\n",
    "## remove low quality sequences\n",
    "genome_table = genome_table[genome_table[\"qc.overallStatus\"] == \"good\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f868752-060b-44ea-932e-2cac33ed2088",
   "metadata": {},
   "source": [
    "### Flatten the CSV file\n",
    " In the nextstrain csv output, some columns (substitutions, deletions, insertion, aa Substitution and aaDeletions) contain a list of variants. To better analyze the data we need to reshape those columns so each sample (one row) can be described as presence or absence of variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d622a5a9-aa98-4cd5-a4d1-948c5f2c50ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## these lines will process the columns which contain lists and expand them\n",
    "genome_table_spread = pd.concat([\n",
    "                 genome_table.drop(['seqName', 'substitutions', 'deletions', 'insertions', 'aaSubstitutions', 'aaDeletions'],axis = 'columns'),\n",
    "                 genome_table['seqName'].str.split(r'\\||/',expand=True).add_prefix('label_'), \n",
    "                 genome_table['substitutions'].apply(lambda x: pd.Series(string2dict2(x,  intro = 'nc_substitutions_'),dtype = int)).fillna(0).astype(int), \n",
    "                 genome_table['deletions'].apply(lambda x: pd.Series(string2dict2(x, intro = 'nc_deletions_') ,dtype = int)).fillna(0).astype(int), \n",
    "                 genome_table['insertions'].apply(lambda x: pd.Series(string2dict2(x,  intro = 'nc_insertions_'),dtype = int)).fillna(0).astype(int), \n",
    "                 genome_table['aaSubstitutions'].apply(lambda x: pd.Series(string2dict2(x,  intro = 'aa_Substitutions_'),dtype = int)).fillna(0).astype(int), \n",
    "                 genome_table['aaDeletions'].apply(lambda x: pd.Series(string2dict2(x,  intro = 'aa_Deletions_'),dtype = int)).fillna(0).astype(int), \n",
    "                 ],axis = 'columns')\n",
    "genome_table_spread = genome_table_spread.dropna(axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3196f724-0a0a-4979-be5c-0b30eed30cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets take a look at the first Sars-CoV-2 see that the sample comes from China from December 2019 from label_3 and label_5\n",
    "genome_table_spread.iloc[0, 30:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974dc7f2-b459-450b-a20d-f0dff54a32ec",
   "metadata": {},
   "source": [
    "## geocoding\n",
    "geocoding is converting an adress to a Latitude and Longitude format. Most geographical plotting software uses the Lat/lon format, so the following lines will do the geocoding using the open street map api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6919d7-9bb7-4faa-8198-79fdfb1a21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### here we are just renaming the label_3 column as the country of origin. the number of the label might change based on how many metadata columns there are.\n",
    "### if using your own data check which column has the country of origin and change it here VVVVVV\n",
    "genome_table_spread['Country'] =                                      genome_table_spread['label_3'].apply(lambda x : x)\n",
    "\n",
    "### this lines does the geocoding for all unique locations (this might take a while! it might timeout if connection is unstable)\n",
    "%time country_loc = {country: geopandas.tools.geocode(country, provider='nominatim', user_agent='autogis_xx', timeout=4).geometry for country in genome_table_spread.Country.unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c76548-58e7-42af-9c71-7f606e87fe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "### this line adds the Lat|Lon to the dataframe if geocoding failed it returns 0,0 as lat|lon\n",
    "genome_table_spread[['Latitude', 'Longitude']] = genome_table_spread.apply(lambda x: getpos(x.Country),   result_type='expand', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ebb741-1912-4703-9e66-574217fa1bfa",
   "metadata": {},
   "source": [
    "### if plottling the data as a scatterplot adding a little variation to the Lat|Lon values will help to visualize points that would overlap otherwise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d81752-e9db-4b1a-8541-45f53efdd1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_table_spread[['lat_jitter', 'long_jitter']] = genome_table_spread.apply(lambda x: [[x.Latitude + np.cos(y)*z, x.Longitude + np.sin(y)*z] \\\n",
    "                                                          for y,z in [(np.random.uniform(0, 2*np.pi), np.random.random())]][0], result_type='expand', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a082866-0286-4df2-8115-ff1d9f3802e0",
   "metadata": {},
   "source": [
    "## fixing datetime columns\n",
    "#### Here we will rearange the datetime format from our dataset. This will also standardize dates for which the day value is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bacce38-28d7-4dbd-8be2-ef16071dd482",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this line reads the dates and makes a standard datetime format\n",
    "genome_table_spread['data_continuous'] = genome_table_spread['label_5'].apply(pd.to_datetime)\n",
    "\n",
    "## this line reads the dates and transforms it into something readable for kepler.gl\n",
    "genome_table_spread['date_kepler'] = genome_table_spread.data_continuous.dt.strftime('%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "## if prefered we can count in days since the first case in the dataset \n",
    "genome_table_spread['days_after_start'] = (genome_table_spread.data_continuous - genome_table_spread.data_continuous.min() ).dt.days\n",
    "\n",
    "## we can also make the continuous date variable into categories, in this case separating into early medium late cases\n",
    "genome_table_spread['data_discrete'] = pd.cut(genome_table_spread['days_after_start'], 5, labels=[\"early\",\"early-medium\" ,\"medium\",'medium-late' ,\"late\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3affdfae-7592-4603-9680-893f33a233f0",
   "metadata": {},
   "source": [
    "# At this point we can already download the data for analysis in excel or Kepler.\n",
    "### Below we can show some analysis and plotting examples that can be of interest but may be easier and more precise to replicate in other software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4c969a-4ad7-478b-994b-b82918aa0855",
   "metadata": {},
   "outputs": [],
   "source": [
    "### download the data\n",
    "genome_table_spread.to_csv('output_LatLon_datetime.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb82bb8-a268-450b-b478-c30346b7e8b0",
   "metadata": {},
   "source": [
    "### Here we can take a look in the mumber of Substitutions over time and per clade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90a7e82-de47-4da5-836a-20ad714cb22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(genome_table_spread, x=\"totalSubstitutions\", color=\"clade\", nbins = 80, title = 'Distribution of Substitutions per lineage')\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=1500,\n",
    "    height=500,)\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d333a2-04f9-4401-8c4b-6e768d33a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### here we can see that the number of mutations increase over time.\n",
    "fig = px.scatter(genome_table_spread, y=\"totalSubstitutions\",x=\"data_continuous\",color=\"clade\", title = 'Number of mutations in Sars-CoV-2 over time')\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=1400,\n",
    "    height=600,)\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b279de-413a-4a5d-b7af-ad3564863ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### here the country id is in label_4 we can change that accodingly depending on your dataset \n",
    "###                       change here     VVVVVV\n",
    "fig = px.scatter(genome_table_spread, y=\"label_4\",x=\"data_continuous\",color=\"clade\", title = 'cases over time per country')\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=1400,\n",
    "    height=600,)\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df62885-b843-4da4-9686-33fb5fff1b5c",
   "metadata": {},
   "source": [
    "# lets chech the countries with most sampling and the variants most common in this sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8336c32d-234e-41c6-b31d-1395d790e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "## here we can do a sunburst plot, which helps us visualize which countries have more samples and which are the most common lineages in each country\n",
    "## to add more features, we can change the path VVVV list to include all columns of interest. Be careful of including only including columns that are categorical\n",
    "fig = px.sunburst(genome_table_spread,          path=['label_4', 'clade', 'label_2'])\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,)\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7f7bf2-a167-4758-a25b-59b5b7dfe21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## here is another was of visualizing the same data from the graph above. Here we conect \n",
    "genome_table_spread['days_after_start'] = (genome_table_spread.data_continuous - genome_table_spread.data_continuous.min() ).dt.days\n",
    "fig = px.parallel_categories(genome_table_spread,  dimensions=['label_4', 'clade','data_discrete'],\n",
    "                             labels={\"label_4\": \"Country\",\"clade\": \"Lineage\"},) #color = 'days_after_start',\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=1400,\n",
    "    height=700,)\n",
    "display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3546cfd-7924-4205-8d6e-cb4f3e7c995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we can see a histogram of the number of samples over time and the frequencies of each lineage\n",
    "fig = px.histogram(genome_table_spread, x=\"data_continuous\", color=\"clade\", nbins = 80).update_xaxes(categoryorder='total descending')\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=1500,\n",
    "    height=600,)\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c1275c-9833-4c14-9e8f-1a0122b39bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we have the same as above but, normalizing the each bar in the histogram to add to 100%\n",
    "fig = px.histogram(genome_table_spread, x=\"data_continuous\", color=\"clade\", barnorm = 'percent', nbins = 40)\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=1400,\n",
    "    height=600,)\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a774425-e2cc-4bd6-9655-05f4c97b9595",
   "metadata": {},
   "source": [
    "### dimesionality reduction using UMAP:\n",
    "##### Dimesionality reduction is a form representing the genomic all mutations in 2 dimensions. Clusters of samples means that the samples in the cluster are genetically similar and the size of the cluster is a form of observing diversity within a group\n",
    "##### This methodology is different from phylogenetic trees and have a different purpose too. See https://www.nature.com/articles/nbt.4314 and https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3989108/. the second paper talks about PCA, which is a different dimensionality reduction algorithm\n",
    "##### The function below allows the user to cluster though\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3051b30-db21-40f0-b2fb-b5cdc29fe18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual(\n",
    "                 maf = widgets.FloatSlider(value=0.01, min=0, max=.5, step=0.01, continuous_update=False, orientation='horizontal', \n",
    "                          readout=True, readout_format='.2f', description = 'Choose maf',layout = layout),\n",
    "                 typ = widgets.RadioButtons(options=  ['nucleotide', 'aminoacid'], value = 'nucleotide', description = 'Choose type of mutation', layout={'width': 'max-content'}),\n",
    "                 n_neighbors = widgets.IntSlider(value=50, min=15, max=150, step=1, continuous_update=False, orientation='horizontal', description = 'n neighbors',layout = layout),\n",
    "                 )\n",
    "def Generate_umap(maf, typ, n_neighbors):\n",
    "    convert = {'nucleotide': 'nc_', 'aminoacid':'aa_'}\n",
    "    nc_mutation_list = [x for x in genome_table_spread.columns if convert[typ] in x and genome_table_spread[x].sum() > genome_table_spread[x].shape[0]*maf]\n",
    "    #print(nc_mutation_list)\n",
    "    umap_embeding = umap.UMAP(n_neighbors= n_neighbors,metric = 'manhattan', densmap = True).fit(genome_table_spread[nc_mutation_list], y)#, \n",
    "                                                                                               #y = preprocessing.LabelEncoder().fit_transform(genome_table_spread.clade))\n",
    "                                                                                                #metric = nextstrain_metric\n",
    "        \n",
    "    genome_table_spread[['UMAP1_nucleotide', 'UMAP2_nucleotide']] = umap_embeding.transform(genome_table_spread[nc_mutation_list])\n",
    "    \n",
    "    fig = px.scatter(genome_table_spread, x=\"UMAP1_nucleotide\", y=\"UMAP2_nucleotide\", color=\"clade\", size='totalSubstitutions', hover_data = ['Country', 'data_continuous'])\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=1000,\n",
    "        height=1000,)\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69176dee-3d90-4858-a373-5af2519f27e6",
   "metadata": {},
   "source": [
    "# Connect closest sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac62bb3-49e5-4bb1-8cf7-aac93e998ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### here we want to create a minimum spanning tree to connect similar samples based on their UMAP values\n",
    "edges = kneighbors_graph(genome_table_spread[['UMAP1_nucleotide','UMAP2_nucleotide']], 200, mode = 'distance', include_self= False, n_jobs = -1)\n",
    "mst_graph = coo_matrix(minimum_spanning_tree(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495db54e-cf9e-42f1-b729-902d4f4cc413",
   "metadata": {},
   "outputs": [],
   "source": [
    "### here we get all the edges from the minimum spanning tree and add to them information about the in and out nodes\n",
    "features_of_interest = ['label_2', 'label_3', 'label_5','Latitude', 'Longitude', 'data_continuous', 'UMAP1_nucleotide', 'UMAP2_nucleotide']\n",
    "%time mst_arrows = pd.DataFrame([genome_table_spread.iloc[i, np.isin(genome_table_spread.columns,features_of_interest)].tolist() \\\n",
    "                                 + genome_table_spread.iloc[j,np.isin(genome_table_spread.columns,features_of_interest)].tolist() \\\n",
    "                                 +[ 100*(1- (k/(k+1)))  ]  \\\n",
    "                                 for i,j, k in zip(mst_graph.col, mst_graph.row, mst_graph.data)], \\\n",
    "                                columns =['in_'+x for x in features_of_interest]+['out_'+x for x in features_of_interest] + ['genetic_similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32dd3ed-6c79-43dc-8642-68a48c0f7ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we save this edge data for vizualization in kepler.gl\n",
    "mst_arrows.to_csv('arrowsAsia.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7199cb-d3c9-4aab-a60e-13d65a2e2423",
   "metadata": {},
   "source": [
    "## edge bundling with datashader\n",
    "#### As the number of samples is quite large, using edge bundling allows us to group edges of our network to better visualize paths. As a warning the path can vary significantly depending on the strength of the bundling. Those parameters can be adjusted within the hammer_bundle function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0780ddb4-104a-448d-9b6b-275624776ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorganize data for datashader package\n",
    "nodes_umap = genome_table_spread[['UMAP1_nucleotide','UMAP2_nucleotide']].reset_index().rename(columns={'index': 'name', 'UMAP1_nucleotide': 'x', 'UMAP2_nucleotide': 'y'})\n",
    "edges_df = pd.DataFrame(zip(mst_graph.row, mst_graph.col, mst_graph.data), columns=['source', 'target', 'weight'])\n",
    "\n",
    "#umap_bundle\n",
    "bundled_points = hammer_bundle(nodes_umap, edges_df, decay= .4, initial_bandwidth = .4, tension = .1)\n",
    "bundleddf =  pd.DataFrame(bundled_points).dropna()\n",
    "\n",
    "#geographical_bundle \n",
    "nodes_spatial = genome_table_spread[['Latitude','Longitude']].reset_index().rename(columns={'index': 'name', 'Latitude': 'x', 'Longitude': 'y'})\n",
    "bundled_points_spatial = hammer_bundle(nodes_spatial, edges_df, decay= .4, initial_bandwidth = .4, tension = .1)\n",
    "\n",
    "# here we save the geographical bundle for visualization in kepler.gl\n",
    "bundleddf_spatial = pd.DataFrame(bundled_points_spatial).dropna()#\n",
    "bundleddf_spatial.to_csv('spatial_bundle.csv')\n",
    "\n",
    "# visualize the genetic path between samples\n",
    "fig = px.scatter(genome_table_spread, x=\"UMAP1_nucleotide\", y=\"UMAP2_nucleotide\", color=\"clade\", size='totalSubstitutions', hover_data = ['Country', 'data_continuous'])\n",
    "fig.add_trace(px.scatter(bundleddf, x=\"x\", y=\"y\").data[0])\n",
    "fig.update_layout( autosize=False,width=1000,height=1000,)\n",
    "\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb27d113-8717-45f4-bfd1-2ff18290f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### save to the main dataframe the UMAP information\n",
    "genome_table_spread.to_csv('output_LatLon_datetime.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fdad34-2329-4624-808a-0a62359cceb9",
   "metadata": {},
   "source": [
    "## now we can plot on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3305ac38-c532-4918-81a2-65b04054af7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### now we can plot on the map \n",
    "fig = px.scatter_mapbox(genome_table_spread, lat=\"lat_jitter\",  lon=\"long_jitter\",  color=\"clade\", size_max=15, title= 'Possible Sars-Cov-2 routes')#size=\"totalSubstitutions\"\n",
    "fig.add_trace(go.Scattermapbox(lon = bundleddf_spatial.y, lat = bundleddf_spatial.x,        \n",
    "                               marker=go.scattermapbox.Marker(size=5, color='gray',opacity=0.3), name = 'edge bundling'))\n",
    "\n",
    "fig.update_layout( autosize=False,width=1300,height=1000, mapbox = {'style':'open-street-map'}) \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce167784-8c71-4619-91d3-22a138e6692b",
   "metadata": {},
   "source": [
    "## Find mutations associated with different groups (simplified GWAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f2fda6-3564-4945-a628-2ab240882427",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### here we can choose 2 groups to find if any of the variants is statistically significant between groups. \n",
    "#####In this example we are comparing samples from Israel and the West Bank for differences. \n",
    "group1 = genome_table_spread.query('label_4 == \"Israel\"')\n",
    "group2 = genome_table_spread.query('label_4 == \"West Bank\"')\n",
    "\n",
    "#####This would be a comparison between samples from Israel and the West Bank for differences. \n",
    "#group1 = genome_table_spread.query('label_4 == \"Israel\"')\n",
    "#group2 = genome_table_spread.query('label_4 == \"West Bank\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1fd919-29ff-40fe-82c6-0eca98b06e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "### this large function will do a t-test for every mutation present in the dataset and output the p-value between groups 1 and 2 above \n",
    "### the user can specify a minor allele frequency to only allow variants that are common\n",
    "\n",
    "@interact_manual(maf = widgets.FloatSlider(value=.05, min=0.0, max=.5, step=0.01, continuous_update=False, orientation='horizontal', \n",
    "                          readout=True, readout_format='.2f', description = 'Choose maf', layout = layout),\n",
    "                 typ = widgets.RadioButtons(options=  ['nucleotide', 'aminoacid'], value = 'nucleotide', description = 'Choose type of mutation', layout={'width': 'max-content'}))\n",
    "def ttest_dataframe(maf, typ):\n",
    "    convert = {'nucleotide': 'nc_', 'aminoacid':'aa_'}\n",
    "    union = pd.concat([group1, group2])\n",
    "    nc_mutation_list = [x for x in union.columns if convert[typ] in x and union[x].sum() > union[x].shape[0]*maf]\n",
    "    output_pvals = {}\n",
    "\n",
    "    for mutation in nc_mutation_list:\n",
    "        pval = ttest_ind(group1[mutation].values, group2[mutation].values, equal_var = False)[1]\n",
    "        if typ == 'nucleotide':output_pvals[mutation] = {'pval': pval if pval>1e-20 else 1e-20, 'pos': int(re.findall(r'\\d+', mutation)[-1])}\n",
    "        else:\n",
    "            gene_pos = mutation.split(':')[0].split('_')[-1]\n",
    "            try:\n",
    "                gene_pos2 = gene_anotations.query(\"@gene_pos in gene\").iloc[0]['start']\n",
    "                output_pvals[mutation] = {'pval': pval if pval >1e-20 else 1e-20, 'pos': gene_pos2+  3*int(re.findall(r'\\d+', mutation)[-1])}\n",
    "            except: pass\n",
    "    significance = pd.DataFrame(output_pvals).T.dropna().sort_values('pval')\n",
    "    significance['-Log10(P-value)'] = -np.log10(significance.pval)\n",
    "    fig = px.scatter(significance, x=\"pos\", y=\"-Log10(P-value)\", hover_data = [significance.index], title = 'Significant Variants between group 1 and group 2')\n",
    "\n",
    "    for num,i in gene_anotations.iterrows():\n",
    "        fig.add_trace(go.Scatter(y=[-1,-1], x = [i.start, i.end], mode=\"lines\",\n",
    "                                 hovertext =i.gene,text=i.gene, name=i.gene ,line = {'width': 10}))\n",
    "    fig.add_trace(go.Scatter(y=[-np.log10(0.05/len(nc_mutation_list)),-np.log10(0.05/len(nc_mutation_list))], x = [0, 29900], mode=\"lines\", \n",
    "                              line = dict(color='firebrick', width=3, dash='dot'), name = 'bonferroni significance'))\n",
    "    fig.update_xaxes(range=[0,29674])\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=1400,\n",
    "        height=800,)\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88057978-d22b-4bef-8755-f3ea00acff44",
   "metadata": {},
   "source": [
    "## Machine Learning example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb730ac-acbf-432e-9f3c-e6009e37fe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@interact_manual(\n",
    "                 maf = widgets.FloatSlider(value=.05, min=0.0, max=.5, step=0.01, continuous_update=False, orientation='horizontal', \n",
    "                          readout=True, readout_format='.2f', description = 'Choose maf',\n",
    "                         layout = layout),\n",
    "                 typ = widgets.RadioButtons(options=  ['nucleotide', 'aminoacid'], value = 'nucleotide', description = 'Choose type of mutation', layout={'width': 'max-content'}),\n",
    "                 col = widgets.Dropdown(options= genome_table_spread.columns), value = 'clade')\n",
    "                 \n",
    "def RunML(maf, typ, col):\n",
    "    too_small = [x[1]['index'] for x in  (genome_table_spread[col].value_counts() > 10).reset_index().iterrows() if not x[1][col]]\n",
    "    df = genome_table_spread.query(\"{0} not in @too_small\".format(col)).copy()\n",
    "    #df = genome_table_spread[genome_table_spread[col] not in too_small]\n",
    "    df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '_', x))\n",
    "\n",
    "    convert = {'nucleotide': 'nc_', 'aminoacid':'aa_'}\n",
    "\n",
    "    nc_mutation_list = [x for x in df.columns if convert[typ] in x and df[x].sum() > df[x].shape[0]*maf]\n",
    "    X = df[nc_mutation_list]\n",
    "    if len(df[col].unique()) < 30: \n",
    "        country_le = preprocessing.LabelEncoder()\n",
    "        Yt = country_le.fit_transform(df[col])\n",
    "        number_labels =list(range(len(country_le.classes_)))\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Yt, test_size=.5, random_state = 63) #, \n",
    "\n",
    "        model = LGBMClassifier()\n",
    "\n",
    "        model.fit(X_train, Y_train)\n",
    "        print('Accuracy score:')\n",
    "        print(accuracy_score(model.predict(X_test), Y_test))\n",
    "        print(classification_report(model.predict(X_test), Y_test, target_names=country_le.inverse_transform(number_labels))  ) \n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 15))\n",
    "        shap.initjs()\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "\n",
    "        shap_values = explainer.shap_values(X)\n",
    "        shap.summary_plot(shap_values, X, plot_size=None, max_display=30, class_names=country_le.inverse_transform(number_labels)) \n",
    "    else:\n",
    "        Yt = df[col]\n",
    "        \n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Yt, test_size=.5, random_state = 63) #, \n",
    "        \n",
    "        model = LGBMRegressor()\n",
    "\n",
    "        model.fit(X_train, Y_train)\n",
    "        #print('Accuracy score:')\n",
    "        #print(accuracy_score(model.predict(X_test), Y_test))\n",
    "        display(pd.DataFrame(cross_validate(model, X, Yt, cv=5,  \n",
    "                       scoring=('neg_mean_absolute_percentage_error','r2','explained_variance', 'max_error', 'neg_mean_absolute_error', 'neg_mean_squared_error'))))\n",
    "\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 15))\n",
    "        shap.initjs()\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "\n",
    "        shap_values = explainer.shap_values(X)\n",
    "        shap.summary_plot(shap_values, X, plot_size=None, max_display=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e24443-d9ac-4332-8fb5-bf322142402b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99ffeb64-e910-4780-881b-99cf5416a779",
   "metadata": {},
   "source": [
    "## calculating tajimas D\n",
    "\n",
    "|Value of Tajima's D |Mathematical reason |Biological interpretation 1 |Biological interpretation 2|\n",
    "|---------------------|--------------------|----------------------------|---------------------------|\n",
    "Tajima's D=0 |Theta-Pi equivalent to Theta-k (Observed=Expected). Average Heterozygosity= # of Segregating sites.|Observed variation similar to expected variation|Population evolving as per mutation-drift equilibrium. No evidence of selection|\n",
    "Tajima's D<0|Theta-Pi less than Theta-k (Observed<Expected). Fewer haplotypes (lower average heterozygosity) than # of segregating sites. |Rare alleles abundant (excess of rare alleles)|Recent selective sweep, population expansion after a recent bottleneck, linkage to a swept gene|\n",
    "Tajima's D>0|Theta-Pi greater than Theta-k (Observed>Expected). More haplotypes (more average heterozygosity)than # of segregating sites.|Rare alleles scarce (lack of rare alleles)|Balancing selection, sudden population contraction|\n",
    "\n",
    "\n",
    "\n",
    "|--|seqid |source |type |start |end |score |strand |phase |ID |gene |Parent|\n",
    "|--|------|-------|-----|------|----|------|-------|------|---|-----|------|         \n",
    "|0 |NC_045512.2 |RefSeq |CDS |13468 |21555 |. |+ |0 |cds-YP_009724389.1 |ORF1ab |gene-GU280_gp01|\n",
    "|1 |NC_045512.2 |RefSeq |CDS |21563 |25384 |. |+ |0 |cds-YP_009724390.1 |S |gene-GU280_gp02|\n",
    "|2 |NC_045512.2 |RefSeq |CDS |25393 |26220 |. |+ |0 |cds-YP_009724391.1 |ORF3a |gene-GU280_gp03|\n",
    "|3 |NC_045512.2 |RefSeq |CDS |26245 |26472 |. |+ |0 |cds-YP_009724392.1 |E |gene-GU280_gp04|\n",
    "|4 |NC_045512.2 |RefSeq |CDS |26523 |27191 |. |+ |0 |cds-YP_009724393.1 |M |gene-GU280_gp05|\n",
    "|5 |NC_045512.2 |RefSeq |CDS |27202 |27387 |. |+ |0 |cds-YP_009724394.1 |ORF6 |gene-GU280_gp06|\n",
    "|6 |NC_045512.2 |RefSeq |CDS |27394 |27759 |. |+ |0 |cds-YP_009724395.1 |ORF7a |gene-GU280_gp07|\n",
    "|7 |NC_045512.2 |RefSeq |CDS |27756 |27887 |. |+ |0 |cds-YP_009725318.1 |ORF7b |gene-GU280_gp08|\n",
    "|8 |NC_045512.2 |RefSeq |CDS |27894 |28259 |. |+ |0 |cds-YP_009724396.1 |ORF8 |gene-GU280_gp09|\n",
    "|9 |NC_045512.2 |RefSeq |CDS |28274 |29533 |. |+ |0 |cds-YP_009724397.2 |N |gene-GU280_gp10|\n",
    "|10|NC_045512.2 |RefSeq |CDS |29558 |29674 |. |+ |0 |cds-YP_009725255.1 |ORF10 |gene-GU280_gp11|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f266a861-4ccd-448b-8351-57245dffe3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual(sample_size = widgets.IntSlider(value=genome_table_spread.shape[1]//5, min=20, max=genome_table_spread.shape[1], step=1, continuous_update=False, \n",
    "                                                 orientation='horizontal', readout=True, description = 'Sample size',layout = layout),\n",
    "                 maf = widgets.FloatSlider(value=.05, min=0.0, max=.5, step=0.001, continuous_update=False, orientation='horizontal', \n",
    "                          readout=True, readout_format='.3f', description = 'Choose maf',layout = layout),\n",
    "                 typ = widgets.RadioButtons(options=  ['nucleotide', 'aminoacid'], value = 'nucleotide', description = 'Choose type of mutation', layout={'width': 'max-content'}),\n",
    "                 range_slide = widgets.IntRangeSlider(value = [21563, 25384], min = 0, max = 29674, description= 'genome position', layout = {'width':'90%'} )\n",
    "                )\n",
    "def Interactive_tajD(sample_size, maf, typ,range_slide):\n",
    "    #dataframe_sample = nucleotide_mutations_table.sample(500)\n",
    "    change = {'nucleotide': 'nc_', 'aminoacid':'aa_'}\n",
    "    dataframe_sample = genome_table_spread[[x for x in genome_table_spread.columns if change[typ] \n",
    "                                            in x and genome_table_spread[x].sum() > genome_table_spread[x].shape[0]*maf]].sample(sample_size)\n",
    "\n",
    "    convert = pd.DataFrame({int(re.findall(r'\\d+', col)[0]):[col]  for col in dataframe_sample.columns }).T.sort_index()\n",
    "\n",
    "    a1 = sum([1/x for x in range(1, dataframe_sample.shape[0])])\n",
    "\n",
    "    def SnPI(table):\n",
    "        S = table.shape[1]\n",
    "        if S == 0: return 0\n",
    "        pairwise_distance_matrix = pairwise_distances(table, metric = 'manhattan',  n_jobs = -1)\n",
    "        pi = pairwise_distance_matrix.sum()/(table.shape[0]**2 - table.shape[0])\n",
    "        return S/a1 - pi\n",
    "\n",
    "    def TajimasD(window, rangee =0):\n",
    "        if rangee == 0: rangee = list(range(window//2, 29904-  window - window//2))\n",
    "        rg = np.array(range(rangee[0], rangee[1]))\n",
    "        theta = np.array([SnPI(dataframe_sample[convert.loc[pos - window//2 :pos+window - window//2, 0]]) for pos in rg])\n",
    "        theta_scaled = (theta - theta.mean())/theta.std()\n",
    "        return pd.DataFrame({'TajimasD': theta_scaled, 'Genome Position': rg})\n",
    "\n",
    "    output = TajimasD(50, range_slide)\n",
    "    fig = px.line(output, x=\"Genome Position\", y=\"TajimasD\", title = \"Tajima's D\")\n",
    "    fig.update_layout( autosize=False,width=1200,height=800,)\n",
    "    for num,i in gene_anotations.iterrows():\n",
    "        fig.add_trace(go.Scatter(y=[0,0], x = [i.start, i.end], mode=\"lines\",\n",
    "                             hovertext =i.gene,text=i.gene, name=i.gene, opacity=0.3 ,line = {'width': 50}))\n",
    "    display(fig)\n",
    "\n",
    "    qqdf = pd.DataFrame(stats.probplot(output['TajimasD'], dist=\"norm\")[0]).T.rename({0: 'expected', 1: 'observed'}, axis = 1)\n",
    "    fig2 = px.scatter(qqdf, x=\"expected\", y=\"observed\", title = 'QQ plot')\n",
    "    fig2.add_trace(go.Scatter(y=[output['TajimasD'].min(),output['TajimasD'].max()], x = [output['TajimasD'].min(), output['TajimasD'].max()], mode=\"lines\",\n",
    "                              line = {'width': 10}, name='Normal distribution'))\n",
    "    fig2.update_layout( autosize=False,width=600,height=600,)\n",
    "    display(fig2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddb0a9c-df9f-4d1f-9240-3302e8a456a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:CoViewer]",
   "language": "python",
   "name": "conda-env-CoViewer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
